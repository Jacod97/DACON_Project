{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96170cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dbb5630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/origin/train.csv\"\n",
    "test_path = \"../data/origin/test.csv\"\n",
    "building_path = \"../data/origin/building_info.csv\"\n",
    "submission_path = \"../data/origin/sample_submission.csv\"\n",
    "\n",
    "ko2en_dict = {\n",
    " '건물번호': 'b_num',\n",
    " '일시': 'date',\n",
    " '기온(°C)': 'tmp',\n",
    " '강수량(mm)': 'rain',\n",
    " '풍속(m/s)': 'wind',\n",
    " '습도(%)': 'hum',\n",
    " '일조(hr)': 'sunshine',\n",
    " '일사(MJ/m2)': 'solar',\n",
    " '전력소비량(kWh)': 'power_consumption',\n",
    " '건물유형': 'b_type',\n",
    " '연면적(m2)': 'total_area',\n",
    " '냉방면적(m2)': 'cooling_area',\n",
    " '태양광용량(kW)': 'solar_capacity',\n",
    " 'ESS저장용량(kWh)': 'ess_capacity',\n",
    " 'PCS용량(kW)': 'pcs_capacity',\n",
    "}\n",
    "\n",
    "change_name = ['hotel', 'commercial', 'hospital', 'school', 'etc', 'apart', 'research', 'store', 'idc','public']\n",
    "\n",
    "train = pd.read_csv(train_path, encoding='utf-8')\n",
    "test = pd.read_csv(test_path, encoding='utf-8')\n",
    "building = pd.read_csv(building_path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6cef18b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_dataframe_columns(df, mapping_dict):\n",
    "    return df.rename(columns=mapping_dict).copy()\n",
    "\n",
    "def add_time(df):\n",
    "    df['datetime'] = pd.to_datetime(df['date'], format='%Y%m%d %H')\n",
    "    df['datetime'] = df['datetime'].dt.strftime(\"%Y-%m-%d %H\")\n",
    "    # df.set_index('datetime', inplace=True)\n",
    "    return df\n",
    "\n",
    "def outlier_process(df, threshold=2.0):\n",
    "    '''이상치 처리 메서드'''\n",
    "    df = df.copy()\n",
    "    for key, group in df.groupby(\"b_num\"):\n",
    "        idx = group.index\n",
    "        vals = group[\"power_consumption\"].to_numpy()\n",
    "        for i in range(1, len(vals) - 1):\n",
    "            if vals[i-1] == 0: \n",
    "                continue\n",
    "            ratio = vals[i] / vals[i-1]\n",
    "            if ratio >= threshold or ratio <= 1/threshold:\n",
    "                vals[i] = (vals[i-1] + vals[i+1]) / 2\n",
    "        df.loc[idx, \"power_consumption\"] = vals\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "75bab7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>b_num</th>\n",
       "      <th>date</th>\n",
       "      <th>tmp</th>\n",
       "      <th>rain</th>\n",
       "      <th>wind</th>\n",
       "      <th>hum</th>\n",
       "      <th>power_consumption</th>\n",
       "      <th>datetime</th>\n",
       "      <th>b_type</th>\n",
       "      <th>total_area</th>\n",
       "      <th>cooling_area</th>\n",
       "      <th>solar_capacity</th>\n",
       "      <th>ess_capacity</th>\n",
       "      <th>pcs_capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20240601 00</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 00</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5794.80</td>\n",
       "      <td>2024-06-01 00</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20240601 01</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 01</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5591.85</td>\n",
       "      <td>2024-06-01 01</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20240601 02</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 02</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5338.17</td>\n",
       "      <td>2024-06-01 02</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20240601 03</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 03</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>81.0</td>\n",
       "      <td>4554.42</td>\n",
       "      <td>2024-06-01 03</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20240601 04</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 04</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3602.25</td>\n",
       "      <td>2024-06-01 04</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_date_time  b_num         date   tmp  rain  wind   hum  \\\n",
       "0  1_20240601 00      1  20240601 00  18.3   0.0   2.6  82.0   \n",
       "1  1_20240601 01      1  20240601 01  18.3   0.0   2.7  82.0   \n",
       "2  1_20240601 02      1  20240601 02  18.1   0.0   2.6  80.0   \n",
       "3  1_20240601 03      1  20240601 03  18.0   0.0   2.6  81.0   \n",
       "4  1_20240601 04      1  20240601 04  17.8   0.0   1.3  81.0   \n",
       "\n",
       "   power_consumption       datetime b_type  total_area  cooling_area  \\\n",
       "0            5794.80  2024-06-01 00  hotel    82912.71       77586.0   \n",
       "1            5591.85  2024-06-01 01  hotel    82912.71       77586.0   \n",
       "2            5338.17  2024-06-01 02  hotel    82912.71       77586.0   \n",
       "3            4554.42  2024-06-01 03  hotel    82912.71       77586.0   \n",
       "4            3602.25  2024-06-01 04  hotel    82912.71       77586.0   \n",
       "\n",
       "  solar_capacity ess_capacity pcs_capacity  \n",
       "0              0            0            0  \n",
       "1              0            0            0  \n",
       "2              0            0            0  \n",
       "3              0            0            0  \n",
       "4              0            0            0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = rename_dataframe_columns(train, ko2en_dict)\n",
    "test_df = rename_dataframe_columns(test, ko2en_dict)\n",
    "building_info_df = rename_dataframe_columns(building, ko2en_dict)\n",
    "\n",
    "train_df = add_time(train_df)\n",
    "test_df = add_time(test_df)\n",
    "\n",
    "train_merge = pd.merge(train_df, building_info_df, on='b_num', how='left')\n",
    "test_merge = pd.merge(test_df, building_info_df, on='b_num', how='left')\n",
    "\n",
    "btypes = list(building_info_df['b_type'].unique())\n",
    "type_map = {bt: change_name[i] for i, bt in enumerate(btypes)}\n",
    "train_merge['b_type'] = train_merge['b_type'].apply(lambda x : type_map[x])\n",
    "test_merge['b_type'] = test_merge['b_type'].apply(lambda x : type_map[x])\n",
    "\n",
    "train_merge = outlier_process(train_merge)\n",
    "\n",
    "train_merge = train_merge.replace(\"-\", 0)\n",
    "test_merge = test_merge.replace(\"-\", 0)\n",
    "\n",
    "train_merge.drop(['sunshine', 'solar'], axis=1, inplace=True)\n",
    "train_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "58420243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalering(df: pd.DataFrame, exclude_cols, scaler,fit):\n",
    "    '''Scalering 적용'''\n",
    "    target_cols = [i for i in df.columns if i not in exclude_cols]\n",
    "    if fit:\n",
    "        df[target_cols] = scaler.fit_transform(df[target_cols])\n",
    "    else:\n",
    "        df[target_cols] = scaler.transform(df[target_cols])\n",
    "    return df\n",
    "\n",
    "def train_validation_split(df, seq_len, ratio=0.8):\n",
    "    '''학습 검증 데이터 분리'''\n",
    "    train_size = int(df.shape[0] * ratio)\n",
    "\n",
    "    train_set = df.iloc[:train_size]\n",
    "    test_set = df.iloc[train_size - seq_len:]\n",
    "    return train_set, test_set\n",
    "\n",
    "def make_dataset(data, seq_length):\n",
    "    '''LSTM 모델 학습을 위한 데이터 셋 구축'''\n",
    "    dataX, dataY = [], []\n",
    "\n",
    "    if 'power_consumption' in data.columns:\n",
    "        for i in range(0, data.shape[0] - seq_length):\n",
    "            x = data.iloc[i:i+seq_length].drop(columns=['power_consumption']).values\n",
    "            y = data.iloc[i+seq_length]['power_consumption']\n",
    "            dataX.append(x)\n",
    "            dataY.append(y)\n",
    "\n",
    "        return np.array(dataX), np.array(dataY).reshape(-1, 1)\n",
    "    else:\n",
    "        for i in range(0, data.shape[0] - seq_length):\n",
    "            x = data.iloc[i:i+seq_length].values   \n",
    "            dataX.append(x)\n",
    "        return np.array(dataX), None \n",
    "\n",
    "def smape_loss(y_true, y_pred):\n",
    "    \"\"\"SMAPE 계산\"\"\"\n",
    "    return 100 * torch.mean(\n",
    "        2 * torch.abs(y_pred - y_true) / (torch.abs(y_true) + torch.abs(y_pred) + 1e-9)\n",
    "    )\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(\n",
    "            self,input_dim,hidden_dim,output_dim,seq_length,layers\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # 속성 저장\n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.seq_length = seq_length \n",
    "        self.layers = layers \n",
    "\n",
    "        # 레이어(batch size)\n",
    "        self.lstm = nn.LSTM(\n",
    "            self.input_dim, \n",
    "            self.hidden_dim,\n",
    "            num_layers=self.layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.linear = nn.Linear(self.hidden_dim, self.output_dim, bias=True)\n",
    "\n",
    "    def reset_hidden_state(self):\n",
    "        \"\"\"LSTM 학습 초기화하는 함수\"\"\"\n",
    "        self.hidden = (\n",
    "            torch.zeros(self.layers, self.seq_length, self.hidden_dim),\n",
    "            torch.zeros(self.layers, self.seq_length, self.hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x[:,-1])\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1f1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hotel is training]\n",
      "[Epoch 1/50] Train Loss: 21747430.8098, Train SMAPE: 189.8904, Val Loss: 3646786.8796, Val SMAPE: 181.6964\n",
      "[Epoch 2/50] Train Loss: 21202662.7537, Train SMAPE: 172.6993, Val Loss: 3374129.4192, Val SMAPE: 166.1855\n",
      "[Epoch 3/50] Train Loss: 20697630.8294, Train SMAPE: 158.4260, Val Loss: 3120355.5198, Val SMAPE: 152.3655\n",
      "[Epoch 4/50] Train Loss: 20215439.5622, Train SMAPE: 146.0171, Val Loss: 2882370.5152, Val SMAPE: 139.8676\n",
      "[Epoch 5/50] Train Loss: 19752627.9604, Train SMAPE: 135.0550, Val Loss: 2658826.7591, Val SMAPE: 128.4744\n",
      "[Epoch 6/50] Train Loss: 19307553.5945, Train SMAPE: 125.3058, Val Loss: 2448855.5861, Val SMAPE: 118.0277\n",
      "[Epoch 7/50] Train Loss: 18879154.0461, Train SMAPE: 116.6614, Val Loss: 2251791.2957, Val SMAPE: 108.4039\n",
      "[Epoch 8/50] Train Loss: 18466634.9138, Train SMAPE: 109.2015, Val Loss: 2067078.3243, Val SMAPE: 99.5031\n",
      "[Epoch 9/50] Train Loss: 18069353.0527, Train SMAPE: 102.7587, Val Loss: 1894230.3251, Val SMAPE: 91.2431\n",
      "[Epoch 10/50] Train Loss: 17686765.4533, Train SMAPE: 97.3145, Val Loss: 1732808.1357, Val SMAPE: 83.5550\n",
      "[Epoch 11/50] Train Loss: 17318397.7196, Train SMAPE: 92.6767, Val Loss: 1582405.2752, Val SMAPE: 76.3803\n",
      "[Epoch 12/50] Train Loss: 16963822.7862, Train SMAPE: 88.7244, Val Loss: 1442638.4585, Val SMAPE: 69.6738\n",
      "[Epoch 13/50] Train Loss: 16622651.9733, Train SMAPE: 85.4270, Val Loss: 1313143.0741, Val SMAPE: 63.4343\n",
      "[Epoch 14/50] Train Loss: 16294526.0954, Train SMAPE: 82.6903, Val Loss: 1193566.3672, Val SMAPE: 57.7009\n",
      "[Epoch 15/50] Train Loss: 15979101.8953, Train SMAPE: 80.3925, Val Loss: 1083564.7631, Val SMAPE: 52.5946\n",
      "[Epoch 16/50] Train Loss: 15676057.0007, Train SMAPE: 78.5376, Val Loss: 982801.8990, Val SMAPE: 48.1254\n",
      "[Epoch 17/50] Train Loss: 15385077.2385, Train SMAPE: 77.1428, Val Loss: 890947.2637, Val SMAPE: 44.2366\n",
      "[Epoch 18/50] Train Loss: 15105860.2485, Train SMAPE: 76.1278, Val Loss: 807669.4920, Val SMAPE: 40.9038\n",
      "[Epoch 19/50] Train Loss: 14838097.6933, Train SMAPE: 75.3698, Val Loss: 732641.1076, Val SMAPE: 38.0061\n",
      "[Epoch 20/50] Train Loss: 14581489.6385, Train SMAPE: 74.7862, Val Loss: 665537.5379, Val SMAPE: 35.5481\n",
      "[Epoch 21/50] Train Loss: 14335735.6866, Train SMAPE: 74.3180, Val Loss: 606031.5612, Val SMAPE: 33.4787\n",
      "[Epoch 22/50] Train Loss: 14100538.4414, Train SMAPE: 73.9400, Val Loss: 553803.7833, Val SMAPE: 31.7783\n",
      "[Epoch 23/50] Train Loss: 13875603.9923, Train SMAPE: 73.6344, Val Loss: 508532.1026, Val SMAPE: 30.4117\n",
      "[Epoch 24/50] Train Loss: 13660634.8262, Train SMAPE: 73.4048, Val Loss: 469894.5091, Val SMAPE: 29.3565\n",
      "[Epoch 25/50] Train Loss: 13455339.1281, Train SMAPE: 73.2447, Val Loss: 437586.5361, Val SMAPE: 28.5959\n",
      "[Epoch 26/50] Train Loss: 13259411.2035, Train SMAPE: 73.1375, Val Loss: 411286.2091, Val SMAPE: 28.0608\n",
      "[Epoch 27/50] Train Loss: 13072560.2285, Train SMAPE: 73.0680, Val Loss: 390685.4305, Val SMAPE: 27.7000\n",
      "[Epoch 28/50] Train Loss: 12894492.8899, Train SMAPE: 73.0346, Val Loss: 375477.6482, Val SMAPE: 27.4770\n",
      "[Epoch 29/50] Train Loss: 12724909.0812, Train SMAPE: 73.0387, Val Loss: 365361.9143, Val SMAPE: 27.3716\n",
      "[Epoch 30/50] Train Loss: 12563517.9940, Train SMAPE: 73.0769, Val Loss: 360041.9839, Val SMAPE: 27.3818\n",
      "[Epoch 31/50] Train Loss: 12410025.7769, Train SMAPE: 73.1451, Val Loss: 359227.8142, Val SMAPE: 27.4910\n",
      "[Epoch 32/50] Train Loss: 12264145.4471, Train SMAPE: 73.2435, Val Loss: 362635.6159, Val SMAPE: 27.6979\n",
      "[Epoch 33/50] Train Loss: 12125590.4366, Train SMAPE: 73.3671, Val Loss: 369988.5035, Val SMAPE: 27.9853\n",
      "[Epoch 34/50] Train Loss: 11994082.3269, Train SMAPE: 73.5088, Val Loss: 381015.7555, Val SMAPE: 28.3544\n",
      "[Epoch 35/50] Train Loss: 11869340.7076, Train SMAPE: 73.6616, Val Loss: 395455.2194, Val SMAPE: 28.7830\n",
      "[Epoch 36/50] Train Loss: 11751088.0536, Train SMAPE: 73.8193, Val Loss: 413055.0143, Val SMAPE: 29.2632\n",
      "[Epoch 37/50] Train Loss: 11639051.5537, Train SMAPE: 73.9833, Val Loss: 433565.6761, Val SMAPE: 29.7830\n",
      "[Epoch 38/50] Train Loss: 11532975.2558, Train SMAPE: 74.1527, Val Loss: 456752.9390, Val SMAPE: 30.3399\n",
      "[Epoch 39/50] Train Loss: 11432594.8530, Train SMAPE: 74.3231, Val Loss: 482389.4741, Val SMAPE: 30.9299\n",
      "[Epoch 40/50] Train Loss: 11337659.7238, Train SMAPE: 74.4949, Val Loss: 510255.4781, Val SMAPE: 31.5530\n",
      "[Epoch 41/50] Train Loss: 11247922.1984, Train SMAPE: 74.6648, Val Loss: 540133.7107, Val SMAPE: 32.2031\n",
      "[Epoch 42/50] Train Loss: 11163145.8076, Train SMAPE: 74.8322, Val Loss: 571842.4880, Val SMAPE: 32.8718\n",
      "[Epoch 43/50] Train Loss: 11083099.4046, Train SMAPE: 74.9973, Val Loss: 605167.3388, Val SMAPE: 33.5563\n",
      "[Epoch 44/50] Train Loss: 11007547.8725, Train SMAPE: 75.1585, Val Loss: 639940.6143, Val SMAPE: 34.2537\n",
      "[Epoch 45/50] Train Loss: 10936279.9896, Train SMAPE: 75.3150, Val Loss: 675998.0789, Val SMAPE: 34.9646\n",
      "[Epoch 46/50] Train Loss: 10869082.6798, Train SMAPE: 75.4656, Val Loss: 713138.4657, Val SMAPE: 35.6850\n",
      "[Epoch 47/50] Train Loss: 10805749.1903, Train SMAPE: 75.6107, Val Loss: 751371.1250, Val SMAPE: 36.4135\n",
      "[Epoch 48/50] Train Loss: 10746085.7720, Train SMAPE: 75.7523, Val Loss: 790253.5587, Val SMAPE: 37.1412\n",
      "[Epoch 49/50] Train Loss: 10689901.4332, Train SMAPE: 75.8900, Val Loss: 829993.8392, Val SMAPE: 37.8655\n",
      "[Epoch 50/50] Train Loss: 10637015.5022, Train SMAPE: 76.0228, Val Loss: 870165.4200, Val SMAPE: 38.5791\n",
      "[hotel] Test 예측 shape: (1656,)\n",
      "========================================================================================================================================================================================================\n",
      "[commercial is training]\n",
      "[Epoch 1/50] Train Loss: 9639628.8464, Train SMAPE: 191.7568, Val Loss: 1829509.4200, Val SMAPE: 167.9802\n",
      "[Epoch 2/50] Train Loss: 9099121.4896, Train SMAPE: 174.1765, Val Loss: 1684334.9535, Val SMAPE: 147.3226\n",
      "[Epoch 3/50] Train Loss: 8623414.6837, Train SMAPE: 160.3174, Val Loss: 1557318.8514, Val SMAPE: 130.2953\n",
      "[Epoch 4/50] Train Loss: 8178012.8677, Train SMAPE: 148.1142, Val Loss: 1445464.6553, Val SMAPE: 115.8510\n",
      "[Epoch 5/50] Train Loss: 7757568.2982, Train SMAPE: 137.1545, Val Loss: 1347322.8690, Val SMAPE: 103.3750\n",
      "[Epoch 6/50] Train Loss: 7359560.6329, Train SMAPE: 127.2017, Val Loss: 1261946.0987, Val SMAPE: 92.5501\n",
      "[Epoch 7/50] Train Loss: 6982375.5164, Train SMAPE: 118.0928, Val Loss: 1188646.8166, Val SMAPE: 84.3658\n",
      "[Epoch 8/50] Train Loss: 6624825.3183, Train SMAPE: 109.7064, Val Loss: 1126983.8567, Val SMAPE: 78.0461\n",
      "[Epoch 9/50] Train Loss: 6285968.7106, Train SMAPE: 101.9882, Val Loss: 1076178.2844, Val SMAPE: 72.6601\n",
      "[Epoch 10/50] Train Loss: 5965022.3148, Train SMAPE: 95.5643, Val Loss: 1035870.0870, Val SMAPE: 68.2909\n",
      "[Epoch 11/50] Train Loss: 5661320.6282, Train SMAPE: 90.0814, Val Loss: 1005588.3599, Val SMAPE: 65.0640\n",
      "[Epoch 12/50] Train Loss: 5374276.4907, Train SMAPE: 85.0845, Val Loss: 984813.9856, Val SMAPE: 63.1333\n",
      "[Epoch 13/50] Train Loss: 5103359.9094, Train SMAPE: 80.4450, Val Loss: 973167.0591, Val SMAPE: 62.6469\n",
      "[Epoch 14/50] Train Loss: 4848084.0348, Train SMAPE: 76.1581, Val Loss: 970183.2281, Val SMAPE: 63.4300\n",
      "[Epoch 15/50] Train Loss: 4607991.0736, Train SMAPE: 72.2428, Val Loss: 975448.1494, Val SMAPE: 65.6457\n",
      "[Epoch 16/50] Train Loss: 4382635.2292, Train SMAPE: 68.6544, Val Loss: 988506.4449, Val SMAPE: 68.4578\n",
      "[Epoch 17/50] Train Loss: 4171578.6826, Train SMAPE: 65.3672, Val Loss: 1008877.6237, Val SMAPE: 71.2564\n",
      "[Epoch 18/50] Train Loss: 3974389.0894, Train SMAPE: 62.3916, Val Loss: 1036089.9499, Val SMAPE: 73.8822\n",
      "[Epoch 19/50] Train Loss: 3790623.2569, Train SMAPE: 59.7240, Val Loss: 1069639.7850, Val SMAPE: 76.3383\n",
      "[Epoch 20/50] Train Loss: 3619830.3734, Train SMAPE: 57.3228, Val Loss: 1109015.1454, Val SMAPE: 78.6340\n",
      "[Epoch 21/50] Train Loss: 3461549.8185, Train SMAPE: 55.1414, Val Loss: 1153688.9815, Val SMAPE: 80.7802\n",
      "[Epoch 22/50] Train Loss: 3315297.6030, Train SMAPE: 53.1522, Val Loss: 1203124.1139, Val SMAPE: 82.7751\n",
      "[Epoch 23/50] Train Loss: 3180583.5746, Train SMAPE: 51.3422, Val Loss: 1256766.3704, Val SMAPE: 84.6351\n",
      "[Epoch 24/50] Train Loss: 3056894.1313, Train SMAPE: 49.7831, Val Loss: 1313978.3544, Val SMAPE: 86.3766\n",
      "[Epoch 25/50] Train Loss: 2943705.0383, Train SMAPE: 48.5756, Val Loss: 1374332.4204, Val SMAPE: 88.0127\n",
      "[Epoch 26/50] Train Loss: 2840478.6106, Train SMAPE: 47.5957, Val Loss: 1437264.5785, Val SMAPE: 89.5476\n",
      "[Epoch 27/50] Train Loss: 2746661.7995, Train SMAPE: 46.7451, Val Loss: 1502208.3963, Val SMAPE: 90.9821\n",
      "[Epoch 28/50] Train Loss: 2661697.7666, Train SMAPE: 46.0051, Val Loss: 1568633.0640, Val SMAPE: 92.3228\n",
      "[Epoch 29/50] Train Loss: 2585018.7708, Train SMAPE: 45.3540, Val Loss: 1636024.9825, Val SMAPE: 93.5739\n",
      "[Epoch 30/50] Train Loss: 2516068.7499, Train SMAPE: 44.7736, Val Loss: 1703892.3392, Val SMAPE: 94.7437\n",
      "[Epoch 31/50] Train Loss: 2454280.1047, Train SMAPE: 44.2599, Val Loss: 1771792.0267, Val SMAPE: 95.8395\n",
      "[Epoch 32/50] Train Loss: 2399108.6962, Train SMAPE: 43.8098, Val Loss: 1839473.4413, Val SMAPE: 96.8683\n",
      "[Epoch 33/50] Train Loss: 2350005.8645, Train SMAPE: 43.4107, Val Loss: 1906282.2348, Val SMAPE: 97.8282\n",
      "[Epoch 34/50] Train Loss: 2306451.4439, Train SMAPE: 43.0569, Val Loss: 1971828.6905, Val SMAPE: 98.7184\n",
      "[Epoch 35/50] Train Loss: 2267946.5455, Train SMAPE: 42.7396, Val Loss: 2035902.5381, Val SMAPE: 99.5438\n",
      "[Epoch 36/50] Train Loss: 2234009.4968, Train SMAPE: 42.4597, Val Loss: 2098297.1875, Val SMAPE: 100.3108\n",
      "[Epoch 37/50] Train Loss: 2204183.3905, Train SMAPE: 42.2094, Val Loss: 2158779.1814, Val SMAPE: 101.0215\n",
      "[Epoch 38/50] Train Loss: 2178046.8545, Train SMAPE: 41.9810, Val Loss: 2217239.5655, Val SMAPE: 101.6864\n",
      "[Epoch 39/50] Train Loss: 2155203.5747, Train SMAPE: 41.7716, Val Loss: 2273367.9466, Val SMAPE: 102.3244\n",
      "[Epoch 40/50] Train Loss: 2135291.0587, Train SMAPE: 41.5790, Val Loss: 2327244.2515, Val SMAPE: 102.9037\n",
      "[Epoch 41/50] Train Loss: 2213259.2305, Train SMAPE: 42.8718, Val Loss: 2218223.5610, Val SMAPE: 103.4065\n",
      "[Epoch 42/50] Train Loss: 2154272.8012, Train SMAPE: 41.7638, Val Loss: 2272002.6494, Val SMAPE: 104.1117\n",
      "[Epoch 43/50] Train Loss: 2113920.1626, Train SMAPE: 41.1408, Val Loss: 2491203.1090, Val SMAPE: 107.1567\n",
      "[Epoch 44/50] Train Loss: 2074087.7974, Train SMAPE: 40.8812, Val Loss: 2533839.1341, Val SMAPE: 107.5296\n",
      "[Epoch 45/50] Train Loss: 2065010.5501, Train SMAPE: 40.7566, Val Loss: 2584049.8872, Val SMAPE: 108.9287\n",
      "[Epoch 46/50] Train Loss: 2057206.7364, Train SMAPE: 40.6421, Val Loss: 2621306.4352, Val SMAPE: 109.2775\n",
      "[Epoch 47/50] Train Loss: 2137669.2213, Train SMAPE: 41.9482, Val Loss: 2455511.5960, Val SMAPE: 106.3242\n",
      "[Epoch 48/50] Train Loss: 2173539.5342, Train SMAPE: 42.4348, Val Loss: 2296896.1982, Val SMAPE: 105.7303\n",
      "[Epoch 49/50] Train Loss: 2321457.4557, Train SMAPE: 44.3738, Val Loss: 2023464.6364, Val SMAPE: 103.0870\n",
      "[Epoch 50/50] Train Loss: 2334494.1749, Train SMAPE: 44.2675, Val Loss: 2020533.4131, Val SMAPE: 108.5275\n",
      "[commercial] Test 예측 shape: (1656,)\n",
      "========================================================================================================================================================================================================\n",
      "[hospital is training]\n",
      "[Epoch 1/50] Train Loss: 52872371.8759, Train SMAPE: 196.4626, Val Loss: 6663713.8294, Val SMAPE: 191.8220\n",
      "[Epoch 2/50] Train Loss: 52318979.5889, Train SMAPE: 187.8782, Val Loss: 6370603.6757, Val SMAPE: 182.0352\n",
      "[Epoch 3/50] Train Loss: 51741061.0185, Train SMAPE: 180.2286, Val Loss: 6084334.9155, Val SMAPE: 172.7591\n",
      "[Epoch 4/50] Train Loss: 51169674.0938, Train SMAPE: 172.9754, Val Loss: 5805931.7669, Val SMAPE: 163.9820\n",
      "[Epoch 5/50] Train Loss: 50607603.3012, Train SMAPE: 166.1024, Val Loss: 5536098.4527, Val SMAPE: 155.6845\n",
      "[Epoch 6/50] Train Loss: 50055910.1881, Train SMAPE: 159.5822, Val Loss: 5275062.6588, Val SMAPE: 147.8362\n",
      "[Epoch 7/50] Train Loss: 49514989.4477, Train SMAPE: 153.3905, Val Loss: 5022849.3826, Val SMAPE: 140.4047\n",
      "[Epoch 8/50] Train Loss: 48984952.5923, Train SMAPE: 147.5046, Val Loss: 4779390.7720, Val SMAPE: 133.3588\n",
      "[Epoch 9/50] Train Loss: 48465776.1995, Train SMAPE: 141.9005, Val Loss: 4544574.0093, Val SMAPE: 126.6694\n",
      "[Epoch 10/50] Train Loss: 47957372.8061, Train SMAPE: 136.5568, Val Loss: 4318261.7694, Val SMAPE: 120.3102\n",
      "[Epoch 11/50] Train Loss: 47459617.3452, Train SMAPE: 131.4550, Val Loss: 4100308.7137, Val SMAPE: 114.2570\n",
      "[Epoch 12/50] Train Loss: 46972371.2116, Train SMAPE: 126.5790, Val Loss: 3890561.8209, Val SMAPE: 108.4882\n",
      "[Epoch 13/50] Train Loss: 46495486.9069, Train SMAPE: 121.9134, Val Loss: 3688867.9286, Val SMAPE: 102.9840\n",
      "[Epoch 14/50] Train Loss: 46028818.7181, Train SMAPE: 117.4441, Val Loss: 3495073.7209, Val SMAPE: 97.7266\n",
      "[Epoch 15/50] Train Loss: 45572214.7623, Train SMAPE: 113.1600, Val Loss: 3309028.4096, Val SMAPE: 92.6998\n",
      "[Epoch 16/50] Train Loss: 45125527.7870, Train SMAPE: 109.0492, Val Loss: 3130578.1909, Val SMAPE: 87.8888\n",
      "[Epoch 17/50] Train Loss: 44688614.1384, Train SMAPE: 105.1071, Val Loss: 2959576.2498, Val SMAPE: 83.2802\n",
      "[Epoch 18/50] Train Loss: 44261331.3477, Train SMAPE: 101.3559, Val Loss: 2795871.9854, Val SMAPE: 78.8631\n",
      "[Epoch 19/50] Train Loss: 43843540.1588, Train SMAPE: 97.8042, Val Loss: 2639322.9297, Val SMAPE: 74.6439\n",
      "[Epoch 20/50] Train Loss: 43435106.0283, Train SMAPE: 94.4282, Val Loss: 2489777.4348, Val SMAPE: 70.6485\n",
      "[Epoch 21/50] Train Loss: 43035880.0612, Train SMAPE: 91.1993, Val Loss: 2347091.9618, Val SMAPE: 66.9089\n",
      "[Epoch 22/50] Train Loss: 42645735.0367, Train SMAPE: 88.1234, Val Loss: 2211122.5436, Val SMAPE: 63.4163\n",
      "[Epoch 23/50] Train Loss: 42264534.1259, Train SMAPE: 85.2112, Val Loss: 2081723.9153, Val SMAPE: 60.1378\n",
      "[Epoch 24/50] Train Loss: 41892137.2942, Train SMAPE: 82.4458, Val Loss: 1958753.9017, Val SMAPE: 57.0163\n",
      "[Epoch 25/50] Train Loss: 41528418.4690, Train SMAPE: 79.8193, Val Loss: 1842069.8361, Val SMAPE: 54.0304\n",
      "[Epoch 26/50] Train Loss: 41173239.2565, Train SMAPE: 77.3334, Val Loss: 1731526.6187, Val SMAPE: 51.1794\n",
      "[Epoch 27/50] Train Loss: 40826463.9351, Train SMAPE: 74.9728, Val Loss: 1626986.5758, Val SMAPE: 48.4569\n",
      "[Epoch 28/50] Train Loss: 40487965.0022, Train SMAPE: 72.7432, Val Loss: 1528305.9592, Val SMAPE: 45.8850\n",
      "[Epoch 29/50] Train Loss: 40157607.1643, Train SMAPE: 70.6391, Val Loss: 1435344.9300, Val SMAPE: 43.4910\n",
      "[Epoch 30/50] Train Loss: 39835257.1263, Train SMAPE: 68.6627, Val Loss: 1347962.7104, Val SMAPE: 41.2892\n",
      "[Epoch 31/50] Train Loss: 39520778.2289, Train SMAPE: 66.8213, Val Loss: 1266019.8800, Val SMAPE: 39.2747\n",
      "[Epoch 32/50] Train Loss: 39214038.9233, Train SMAPE: 65.1098, Val Loss: 1189378.2270, Val SMAPE: 37.4679\n",
      "[Epoch 33/50] Train Loss: 38914907.8650, Train SMAPE: 63.5066, Val Loss: 1117900.2374, Val SMAPE: 35.8215\n",
      "[Epoch 34/50] Train Loss: 38623248.1323, Train SMAPE: 62.0131, Val Loss: 1051447.7745, Val SMAPE: 34.3441\n",
      "[Epoch 35/50] Train Loss: 38338931.4907, Train SMAPE: 60.6176, Val Loss: 989886.8517, Val SMAPE: 33.0288\n",
      "[Epoch 36/50] Train Loss: 38061824.3956, Train SMAPE: 59.3213, Val Loss: 933079.4443, Val SMAPE: 31.8913\n",
      "[Epoch 37/50] Train Loss: 37791788.4052, Train SMAPE: 58.1198, Val Loss: 880894.1911, Val SMAPE: 30.9114\n",
      "[Epoch 38/50] Train Loss: 37528761.2946, Train SMAPE: 57.0069, Val Loss: 833217.0922, Val SMAPE: 30.0690\n",
      "[Epoch 39/50] Train Loss: 37274672.9767, Train SMAPE: 55.9472, Val Loss: 789814.5081, Val SMAPE: 29.3467\n",
      "[Epoch 40/50] Train Loss: 37026362.4023, Train SMAPE: 54.9686, Val Loss: 750571.5768, Val SMAPE: 28.7230\n",
      "[Epoch 41/50] Train Loss: 36775697.9474, Train SMAPE: 54.0090, Val Loss: 729013.7141, Val SMAPE: 28.5325\n",
      "[Epoch 42/50] Train Loss: 36535971.5931, Train SMAPE: 53.0321, Val Loss: 701257.6132, Val SMAPE: 28.1380\n",
      "[Epoch 43/50] Train Loss: 36296656.3504, Train SMAPE: 52.1743, Val Loss: 712222.3595, Val SMAPE: 28.5258\n",
      "[Epoch 44/50] Train Loss: 36059731.2883, Train SMAPE: 51.0083, Val Loss: 661984.3661, Val SMAPE: 27.6859\n",
      "[Epoch 45/50] Train Loss: 35828583.4112, Train SMAPE: 50.0662, Val Loss: 651810.3120, Val SMAPE: 27.6522\n",
      "[Epoch 46/50] Train Loss: 35602085.0450, Train SMAPE: 49.3377, Val Loss: 601811.3087, Val SMAPE: 26.4793\n",
      "[Epoch 47/50] Train Loss: 35385320.7882, Train SMAPE: 48.6341, Val Loss: 611238.9016, Val SMAPE: 26.9055\n",
      "[Epoch 48/50] Train Loss: 35173146.9969, Train SMAPE: 47.9353, Val Loss: 590618.0401, Val SMAPE: 26.4235\n",
      "[Epoch 49/50] Train Loss: 34986597.3305, Train SMAPE: 47.5453, Val Loss: 610278.9791, Val SMAPE: 26.9833\n",
      "[Epoch 50/50] Train Loss: 34759887.5920, Train SMAPE: 46.8081, Val Loss: 610426.7650, Val SMAPE: 27.0551\n",
      "[hospital] Test 예측 shape: (1488,)\n",
      "========================================================================================================================================================================================================\n",
      "[school is training]\n",
      "[Epoch 1/50] Train Loss: 21441615.1004, Train SMAPE: 190.8028, Val Loss: 8521724.9291, Val SMAPE: 182.1323\n",
      "[Epoch 2/50] Train Loss: 20819789.8233, Train SMAPE: 173.4355, Val Loss: 8109689.9489, Val SMAPE: 167.6468\n",
      "[Epoch 3/50] Train Loss: 20258610.9479, Train SMAPE: 159.6857, Val Loss: 7724854.0168, Val SMAPE: 154.9474\n",
      "[Epoch 4/50] Train Loss: 19725651.9146, Train SMAPE: 147.8164, Val Loss: 7360464.8990, Val SMAPE: 143.5553\n",
      "[Epoch 5/50] Train Loss: 19215042.2388, Train SMAPE: 137.3371, Val Loss: 7014060.1109, Val SMAPE: 133.2188\n",
      "[Epoch 6/50] Train Loss: 18724309.4777, Train SMAPE: 127.9545, Val Loss: 6684257.4604, Val SMAPE: 123.7666\n",
      "[Epoch 7/50] Train Loss: 18251995.3582, Train SMAPE: 119.6890, Val Loss: 6370102.6296, Val SMAPE: 115.0703\n",
      "[Epoch 8/50] Train Loss: 17797084.4446, Train SMAPE: 112.7389, Val Loss: 6070864.0396, Val SMAPE: 107.0300\n",
      "[Epoch 9/50] Train Loss: 17358799.8790, Train SMAPE: 106.9569, Val Loss: 5785938.0468, Val SMAPE: 99.5652\n",
      "[Epoch 10/50] Train Loss: 16936511.4574, Train SMAPE: 102.0898, Val Loss: 5514807.9915, Val SMAPE: 92.6116\n",
      "[Epoch 11/50] Train Loss: 16529684.9004, Train SMAPE: 97.9016, Val Loss: 5257013.1559, Val SMAPE: 86.1521\n",
      "[Epoch 12/50] Train Loss: 16137855.4778, Train SMAPE: 94.3370, Val Loss: 5012137.0058, Val SMAPE: 80.3575\n",
      "[Epoch 13/50] Train Loss: 15760612.7453, Train SMAPE: 91.3143, Val Loss: 4779795.1960, Val SMAPE: 75.5599\n",
      "[Epoch 14/50] Train Loss: 15397579.4199, Train SMAPE: 88.6768, Val Loss: 4559618.0591, Val SMAPE: 71.6930\n",
      "[Epoch 15/50] Train Loss: 15048402.5611, Train SMAPE: 86.3864, Val Loss: 4351258.5751, Val SMAPE: 68.5961\n",
      "[Epoch 16/50] Train Loss: 14862464.4879, Train SMAPE: 84.6153, Val Loss: 4385369.4867, Val SMAPE: 69.1501\n",
      "[Epoch 17/50] Train Loss: 16872021.8584, Train SMAPE: 100.3248, Val Loss: 4623813.2149, Val SMAPE: 72.9022\n",
      "[Epoch 18/50] Train Loss: 15103490.2754, Train SMAPE: 86.5190, Val Loss: 4393063.2439, Val SMAPE: 69.1820\n",
      "[Epoch 19/50] Train Loss: 14722096.6640, Train SMAPE: 84.2681, Val Loss: 4137067.9492, Val SMAPE: 66.0179\n",
      "[Epoch 20/50] Train Loss: 14366964.1578, Train SMAPE: 82.5445, Val Loss: 3966961.9955, Val SMAPE: 64.1812\n",
      "[Epoch 21/50] Train Loss: 14093368.8843, Train SMAPE: 81.3928, Val Loss: 3812644.1370, Val SMAPE: 62.7275\n",
      "[Epoch 22/50] Train Loss: 13829306.9156, Train SMAPE: 80.1846, Val Loss: 3664487.4058, Val SMAPE: 61.4578\n",
      "[Epoch 23/50] Train Loss: 13576760.4512, Train SMAPE: 79.3797, Val Loss: 3527857.8504, Val SMAPE: 60.4030\n",
      "[Epoch 24/50] Train Loss: 13313814.3900, Train SMAPE: 78.2038, Val Loss: 3366538.7812, Val SMAPE: 59.2438\n",
      "[Epoch 25/50] Train Loss: 13036152.5935, Train SMAPE: 77.1849, Val Loss: 3272247.2599, Val SMAPE: 58.5709\n",
      "[Epoch 26/50] Train Loss: 12800386.6614, Train SMAPE: 76.2663, Val Loss: 3176838.1568, Val SMAPE: 57.8356\n",
      "[Epoch 27/50] Train Loss: 12589379.9395, Train SMAPE: 75.4293, Val Loss: 3066721.0899, Val SMAPE: 57.0568\n",
      "[Epoch 28/50] Train Loss: 12366931.1883, Train SMAPE: 75.0992, Val Loss: 2942969.6970, Val SMAPE: 56.2963\n",
      "[Epoch 29/50] Train Loss: 12162543.7780, Train SMAPE: 74.6051, Val Loss: 2851312.6921, Val SMAPE: 55.5481\n",
      "[Epoch 30/50] Train Loss: 11966578.7620, Train SMAPE: 74.2287, Val Loss: 2804580.9196, Val SMAPE: 55.2692\n",
      "[Epoch 31/50] Train Loss: 11712177.3557, Train SMAPE: 73.4511, Val Loss: 2730930.5015, Val SMAPE: 54.7343\n",
      "[Epoch 32/50] Train Loss: 11554525.5291, Train SMAPE: 73.1820, Val Loss: 2672105.8598, Val SMAPE: 54.4468\n",
      "[Epoch 33/50] Train Loss: 11338212.8085, Train SMAPE: 72.3768, Val Loss: 2688281.0293, Val SMAPE: 54.4263\n",
      "[Epoch 34/50] Train Loss: 11138910.1580, Train SMAPE: 71.5287, Val Loss: 2730701.8521, Val SMAPE: 54.8860\n",
      "[Epoch 35/50] Train Loss: 10952869.3059, Train SMAPE: 70.8313, Val Loss: 2653187.6528, Val SMAPE: 54.2859\n",
      "[Epoch 36/50] Train Loss: 10788654.5551, Train SMAPE: 70.5299, Val Loss: 2603223.7767, Val SMAPE: 54.0136\n",
      "[Epoch 37/50] Train Loss: 10655448.4108, Train SMAPE: 70.2083, Val Loss: 2512523.6806, Val SMAPE: 53.2416\n",
      "[Epoch 38/50] Train Loss: 10442441.9496, Train SMAPE: 69.0599, Val Loss: 2726606.7593, Val SMAPE: 54.8526\n",
      "[Epoch 39/50] Train Loss: 10232467.6635, Train SMAPE: 67.5710, Val Loss: 2616829.5675, Val SMAPE: 53.7841\n",
      "[Epoch 40/50] Train Loss: 10096342.0246, Train SMAPE: 67.9450, Val Loss: 2589071.3056, Val SMAPE: 53.7637\n",
      "[Epoch 41/50] Train Loss: 9915347.4152, Train SMAPE: 66.6311, Val Loss: 2653798.7740, Val SMAPE: 54.3481\n",
      "[Epoch 42/50] Train Loss: 9653897.7669, Train SMAPE: 64.7483, Val Loss: 2595521.7275, Val SMAPE: 53.9344\n",
      "[Epoch 43/50] Train Loss: 9471428.2208, Train SMAPE: 63.5252, Val Loss: 2646171.0141, Val SMAPE: 54.2833\n",
      "[Epoch 44/50] Train Loss: 9311196.5556, Train SMAPE: 62.9876, Val Loss: 2589394.7591, Val SMAPE: 53.8652\n",
      "[Epoch 45/50] Train Loss: 9168663.0782, Train SMAPE: 62.7160, Val Loss: 2538396.3845, Val SMAPE: 53.5122\n",
      "[Epoch 46/50] Train Loss: 9028448.2896, Train SMAPE: 62.4463, Val Loss: 2489033.1368, Val SMAPE: 53.1500\n",
      "[Epoch 47/50] Train Loss: 8905923.1279, Train SMAPE: 62.1227, Val Loss: 2587582.4188, Val SMAPE: 53.7679\n",
      "[Epoch 48/50] Train Loss: 8693065.5225, Train SMAPE: 60.1881, Val Loss: 2571194.0015, Val SMAPE: 53.7483\n",
      "[Epoch 49/50] Train Loss: 8524739.4150, Train SMAPE: 58.8262, Val Loss: 2676389.8064, Val SMAPE: 54.4893\n",
      "[Epoch 50/50] Train Loss: 8363327.3870, Train SMAPE: 58.0177, Val Loss: 2635179.5354, Val SMAPE: 54.2175\n",
      "[school] Test 예측 shape: (1656,)\n",
      "========================================================================================================================================================================================================\n",
      "[etc is training]\n",
      "[Epoch 1/50] Train Loss: 12008628.8082, Train SMAPE: 186.7334, Val Loss: 1403524.7252, Val SMAPE: 181.3393\n",
      "[Epoch 2/50] Train Loss: 11609653.7024, Train SMAPE: 165.6727, Val Loss: 1292370.1917, Val SMAPE: 167.9143\n",
      "[Epoch 3/50] Train Loss: 11254198.9035, Train SMAPE: 149.1936, Val Loss: 1196212.1128, Val SMAPE: 156.8900\n",
      "[Epoch 4/50] Train Loss: 10920032.5395, Train SMAPE: 135.1396, Val Loss: 1107392.3775, Val SMAPE: 147.0752\n",
      "[Epoch 5/50] Train Loss: 10603860.5168, Train SMAPE: 122.8861, Val Loss: 1026747.7007, Val SMAPE: 138.5727\n",
      "[Epoch 6/50] Train Loss: 10304135.6389, Train SMAPE: 112.0916, Val Loss: 953577.1519, Val SMAPE: 131.0462\n",
      "[Epoch 7/50] Train Loss: 10019805.7939, Train SMAPE: 103.0128, Val Loss: 887475.1679, Val SMAPE: 124.4906\n",
      "[Epoch 8/50] Train Loss: 9750044.2046, Train SMAPE: 95.8969, Val Loss: 828042.4000, Val SMAPE: 118.8851\n",
      "[Epoch 9/50] Train Loss: 9494153.6521, Train SMAPE: 89.9068, Val Loss: 775028.9132, Val SMAPE: 114.1218\n",
      "[Epoch 10/50] Train Loss: 9251521.1252, Train SMAPE: 84.7916, Val Loss: 728249.8895, Val SMAPE: 109.9987\n",
      "[Epoch 11/50] Train Loss: 9021595.1674, Train SMAPE: 80.6365, Val Loss: 688086.5812, Val SMAPE: 106.3845\n",
      "[Epoch 12/50] Train Loss: 8803866.4407, Train SMAPE: 77.3453, Val Loss: 652632.0059, Val SMAPE: 103.0587\n",
      "[Epoch 13/50] Train Loss: 8597859.5096, Train SMAPE: 74.7397, Val Loss: 622483.0566, Val SMAPE: 100.2712\n",
      "[Epoch 14/50] Train Loss: 8403122.7652, Train SMAPE: 72.6122, Val Loss: 596824.3112, Val SMAPE: 97.7933\n",
      "[Epoch 15/50] Train Loss: 8219221.6025, Train SMAPE: 70.8121, Val Loss: 575404.4098, Val SMAPE: 95.6612\n",
      "[Epoch 16/50] Train Loss: 8045733.9763, Train SMAPE: 69.2894, Val Loss: 558847.8898, Val SMAPE: 94.0065\n",
      "[Epoch 17/50] Train Loss: 7882253.7535, Train SMAPE: 68.0218, Val Loss: 545722.0797, Val SMAPE: 92.6194\n",
      "[Epoch 18/50] Train Loss: 7728376.1630, Train SMAPE: 66.9655, Val Loss: 536351.7957, Val SMAPE: 91.5515\n",
      "[Epoch 19/50] Train Loss: 7583700.4598, Train SMAPE: 66.1012, Val Loss: 530526.9886, Val SMAPE: 90.7990\n",
      "[Epoch 20/50] Train Loss: 7447839.1808, Train SMAPE: 65.4076, Val Loss: 527930.3318, Val SMAPE: 90.2695\n",
      "[Epoch 21/50] Train Loss: 7320399.1615, Train SMAPE: 64.8621, Val Loss: 528336.6545, Val SMAPE: 89.9828\n",
      "[Epoch 22/50] Train Loss: 7200999.5571, Train SMAPE: 64.4499, Val Loss: 531477.0316, Val SMAPE: 89.9269\n",
      "[Epoch 23/50] Train Loss: 7089265.2665, Train SMAPE: 64.1434, Val Loss: 537182.4115, Val SMAPE: 90.1240\n",
      "[Epoch 24/50] Train Loss: 6984824.2778, Train SMAPE: 63.9166, Val Loss: 545269.0355, Val SMAPE: 90.3845\n",
      "[Epoch 25/50] Train Loss: 6887308.3621, Train SMAPE: 63.7552, Val Loss: 555523.1137, Val SMAPE: 90.8327\n",
      "[Epoch 26/50] Train Loss: 6796361.9270, Train SMAPE: 63.6503, Val Loss: 567749.8972, Val SMAPE: 91.3605\n",
      "[Epoch 27/50] Train Loss: 6711634.2382, Train SMAPE: 63.5965, Val Loss: 583459.3921, Val SMAPE: 92.8803\n",
      "[Epoch 28/50] Train Loss: 6632779.4975, Train SMAPE: 63.5877, Val Loss: 598441.6938, Val SMAPE: 93.4869\n",
      "[Epoch 29/50] Train Loss: 6559467.4380, Train SMAPE: 63.6162, Val Loss: 614916.9326, Val SMAPE: 94.2118\n",
      "[Epoch 30/50] Train Loss: 6491373.4386, Train SMAPE: 63.6812, Val Loss: 632506.8079, Val SMAPE: 94.9749\n",
      "[Epoch 31/50] Train Loss: 6428189.3403, Train SMAPE: 63.7811, Val Loss: 650989.4385, Val SMAPE: 95.7742\n",
      "[Epoch 32/50] Train Loss: 6369612.5431, Train SMAPE: 63.9149, Val Loss: 670413.6831, Val SMAPE: 96.4764\n",
      "[Epoch 33/50] Train Loss: 6315352.9072, Train SMAPE: 64.0789, Val Loss: 690574.3511, Val SMAPE: 97.2916\n",
      "[Epoch 34/50] Train Loss: 6265135.8378, Train SMAPE: 64.2681, Val Loss: 711318.5221, Val SMAPE: 98.0992\n",
      "[Epoch 35/50] Train Loss: 6218696.4256, Train SMAPE: 64.4823, Val Loss: 732072.4819, Val SMAPE: 98.8767\n",
      "[Epoch 36/50] Train Loss: 6175784.5420, Train SMAPE: 64.7110, Val Loss: 750978.9261, Val SMAPE: 99.3904\n",
      "[Epoch 37/50] Train Loss: 6136159.1853, Train SMAPE: 64.9497, Val Loss: 771776.1614, Val SMAPE: 100.3884\n",
      "[Epoch 38/50] Train Loss: 6099067.3099, Train SMAPE: 65.1417, Val Loss: 797604.4388, Val SMAPE: 102.5577\n",
      "[Epoch 39/50] Train Loss: 6045170.9231, Train SMAPE: 65.0150, Val Loss: 731414.6677, Val SMAPE: 100.0543\n",
      "[Epoch 40/50] Train Loss: 6010635.9866, Train SMAPE: 63.8527, Val Loss: 642123.1179, Val SMAPE: 96.1448\n",
      "[Epoch 41/50] Train Loss: 5994328.6526, Train SMAPE: 64.6990, Val Loss: 732318.4770, Val SMAPE: 101.0141\n",
      "[Epoch 42/50] Train Loss: 5968695.1427, Train SMAPE: 65.6311, Val Loss: 779810.5802, Val SMAPE: 104.2497\n",
      "[Epoch 43/50] Train Loss: 5946873.6178, Train SMAPE: 66.1057, Val Loss: 842449.5206, Val SMAPE: 106.6227\n",
      "[Epoch 44/50] Train Loss: 6516671.8672, Train SMAPE: 70.8245, Val Loss: 463236.1628, Val SMAPE: 73.9909\n",
      "[Epoch 45/50] Train Loss: 6650648.9453, Train SMAPE: 63.5752, Val Loss: 470674.1452, Val SMAPE: 74.4791\n",
      "[Epoch 46/50] Train Loss: 6399189.0399, Train SMAPE: 62.6637, Val Loss: 498833.0256, Val SMAPE: 79.7990\n",
      "[Epoch 47/50] Train Loss: 6185477.8564, Train SMAPE: 61.8668, Val Loss: 488976.4188, Val SMAPE: 77.8872\n",
      "[Epoch 48/50] Train Loss: 6086200.0471, Train SMAPE: 61.4511, Val Loss: 485346.6845, Val SMAPE: 77.4901\n",
      "[Epoch 49/50] Train Loss: 5999658.9716, Train SMAPE: 61.0309, Val Loss: 472767.9735, Val SMAPE: 75.8543\n",
      "[Epoch 50/50] Train Loss: 5922359.9768, Train SMAPE: 60.8600, Val Loss: 486395.1895, Val SMAPE: 77.7722\n",
      "[etc] Test 예측 shape: (1656,)\n",
      "========================================================================================================================================================================================================\n",
      "[apart is training]\n",
      "[Epoch 1/50] Train Loss: 1668409.2443, Train SMAPE: 153.3579, Val Loss: 2552710.7280, Val SMAPE: 180.2620\n",
      "[Epoch 2/50] Train Loss: 1543646.6992, Train SMAPE: 152.1048, Val Loss: 2357442.4806, Val SMAPE: 164.8263\n",
      "[Epoch 3/50] Train Loss: 1436306.3769, Train SMAPE: 145.3510, Val Loss: 2181249.1486, Val SMAPE: 151.4571\n",
      "[Epoch 4/50] Train Loss: 1342215.6073, Train SMAPE: 137.6100, Val Loss: 2021583.6605, Val SMAPE: 139.7361\n",
      "[Epoch 5/50] Train Loss: 1259815.2888, Train SMAPE: 130.1733, Val Loss: 1876836.8049, Val SMAPE: 129.3875\n",
      "[Epoch 6/50] Train Loss: 1187851.6245, Train SMAPE: 123.3450, Val Loss: 1745695.4831, Val SMAPE: 120.2044\n",
      "[Epoch 7/50] Train Loss: 1125223.1772, Train SMAPE: 117.1789, Val Loss: 1627012.5549, Val SMAPE: 112.0246\n",
      "[Epoch 8/50] Train Loss: 1070937.8823, Train SMAPE: 111.6764, Val Loss: 1519759.2234, Val SMAPE: 104.7181\n",
      "[Epoch 9/50] Train Loss: 1024092.0926, Train SMAPE: 106.8481, Val Loss: 1422997.0144, Val SMAPE: 98.1788\n",
      "[Epoch 10/50] Train Loss: 983857.0444, Train SMAPE: 102.6742, Val Loss: 1335860.4641, Val SMAPE: 92.3184\n",
      "[Epoch 11/50] Train Loss: 949471.0292, Train SMAPE: 99.0945, Val Loss: 1257544.8015, Val SMAPE: 87.0625\n",
      "[Epoch 12/50] Train Loss: 920233.4334, Train SMAPE: 96.0798, Val Loss: 1187296.2863, Val SMAPE: 82.3476\n",
      "[Epoch 13/50] Train Loss: 895500.7412, Train SMAPE: 93.5639, Val Loss: 1124407.3328, Val SMAPE: 78.1181\n",
      "[Epoch 14/50] Train Loss: 874685.6447, Train SMAPE: 91.4833, Val Loss: 1068214.2677, Val SMAPE: 74.3257\n",
      "[Epoch 15/50] Train Loss: 857254.7278, Train SMAPE: 89.7763, Val Loss: 1018092.9827, Val SMAPE: 70.9271\n",
      "[Epoch 16/50] Train Loss: 842727.1743, Train SMAPE: 88.3724, Val Loss: 973458.3273, Val SMAPE: 67.8834\n",
      "[Epoch 17/50] Train Loss: 830673.4759, Train SMAPE: 87.2188, Val Loss: 933764.2508, Val SMAPE: 65.1613\n",
      "[Epoch 18/50] Train Loss: 820713.5839, Train SMAPE: 86.2712, Val Loss: 898508.5057, Val SMAPE: 62.7389\n",
      "[Epoch 19/50] Train Loss: 812515.2143, Train SMAPE: 85.4886, Val Loss: 867222.7215, Val SMAPE: 60.5888\n",
      "[Epoch 20/50] Train Loss: 805789.2494, Train SMAPE: 84.8350, Val Loss: 839481.7486, Val SMAPE: 58.6906\n",
      "[Epoch 21/50] Train Loss: 800287.4980, Train SMAPE: 84.2926, Val Loss: 814896.1407, Val SMAPE: 57.0188\n",
      "[Epoch 22/50] Train Loss: 795798.5015, Train SMAPE: 83.8444, Val Loss: 793114.8135, Val SMAPE: 55.5354\n",
      "[Epoch 23/50] Train Loss: 792143.7245, Train SMAPE: 83.4802, Val Loss: 773820.4930, Val SMAPE: 54.2223\n",
      "[Epoch 24/50] Train Loss: 789173.0035, Train SMAPE: 83.1823, Val Loss: 756728.5434, Val SMAPE: 53.0587\n",
      "[Epoch 25/50] Train Loss: 786763.7490, Train SMAPE: 82.9354, Val Loss: 741591.9080, Val SMAPE: 52.0256\n",
      "[Epoch 26/50] Train Loss: 784806.3170, Train SMAPE: 82.7315, Val Loss: 728173.7307, Val SMAPE: 51.1105\n",
      "[Epoch 27/50] Train Loss: 790290.8118, Train SMAPE: 83.0461, Val Loss: 755635.6834, Val SMAPE: 52.9829\n",
      "[Epoch 28/50] Train Loss: 786557.2117, Train SMAPE: 82.9206, Val Loss: 740957.8404, Val SMAPE: 51.9795\n",
      "[Epoch 29/50] Train Loss: 784635.9445, Train SMAPE: 82.7219, Val Loss: 727876.5922, Val SMAPE: 51.0849\n",
      "[Epoch 30/50] Train Loss: 779172.3687, Train SMAPE: 82.2632, Val Loss: 679666.7092, Val SMAPE: 47.8295\n",
      "[Epoch 31/50] Train Loss: 801421.4794, Train SMAPE: 83.7646, Val Loss: 864175.8115, Val SMAPE: 59.8946\n",
      "[Epoch 32/50] Train Loss: 792083.8375, Train SMAPE: 83.4955, Val Loss: 842724.9076, Val SMAPE: 58.3922\n",
      "[Epoch 33/50] Train Loss: 786515.8631, Train SMAPE: 82.9237, Val Loss: 787785.3092, Val SMAPE: 54.6321\n",
      "[Epoch 34/50] Train Loss: 782010.2493, Train SMAPE: 82.4428, Val Loss: 775943.8133, Val SMAPE: 53.7901\n",
      "[Epoch 35/50] Train Loss: 778985.9771, Train SMAPE: 82.0945, Val Loss: 731730.7760, Val SMAPE: 50.8446\n",
      "[Epoch 36/50] Train Loss: 779934.7513, Train SMAPE: 81.7077, Val Loss: 697414.3771, Val SMAPE: 48.7192\n",
      "[Epoch 37/50] Train Loss: 770139.7012, Train SMAPE: 81.4164, Val Loss: 694725.1018, Val SMAPE: 48.5806\n",
      "[Epoch 38/50] Train Loss: 770903.6629, Train SMAPE: 81.4715, Val Loss: 689043.0736, Val SMAPE: 48.1363\n",
      "[Epoch 39/50] Train Loss: 775951.5095, Train SMAPE: 81.4466, Val Loss: 703639.2740, Val SMAPE: 49.2691\n",
      "[Epoch 40/50] Train Loss: 769140.2194, Train SMAPE: 82.0029, Val Loss: 616502.4596, Val SMAPE: 43.8476\n",
      "[Epoch 41/50] Train Loss: 757753.7882, Train SMAPE: 81.5670, Val Loss: 694364.8898, Val SMAPE: 48.8119\n",
      "[Epoch 42/50] Train Loss: 760813.4988, Train SMAPE: 81.7342, Val Loss: 687802.4739, Val SMAPE: 48.3979\n",
      "[Epoch 43/50] Train Loss: 760133.9198, Train SMAPE: 81.6502, Val Loss: 681121.6295, Val SMAPE: 47.9351\n",
      "[Epoch 44/50] Train Loss: 756021.4911, Train SMAPE: 81.4886, Val Loss: 675984.5278, Val SMAPE: 47.6113\n",
      "[Epoch 45/50] Train Loss: 753466.0719, Train SMAPE: 81.3311, Val Loss: 671246.6178, Val SMAPE: 47.2930\n",
      "[Epoch 46/50] Train Loss: 751709.5324, Train SMAPE: 81.2513, Val Loss: 668364.9885, Val SMAPE: 47.1469\n",
      "[Epoch 47/50] Train Loss: 742417.1172, Train SMAPE: 81.0964, Val Loss: 662705.2046, Val SMAPE: 46.7655\n",
      "[Epoch 48/50] Train Loss: 747203.2699, Train SMAPE: 81.0208, Val Loss: 660691.6565, Val SMAPE: 46.6732\n",
      "[Epoch 49/50] Train Loss: 741621.4995, Train SMAPE: 80.9919, Val Loss: 663962.8941, Val SMAPE: 46.8630\n",
      "[Epoch 50/50] Train Loss: 730740.8989, Train SMAPE: 80.8349, Val Loss: 692531.3403, Val SMAPE: 48.7035\n",
      "[apart] Test 예측 shape: (1488,)\n",
      "========================================================================================================================================================================================================\n",
      "[research is training]\n",
      "[Epoch 1/50] Train Loss: 5217139.9897, Train SMAPE: 188.8872, Val Loss: 4786530.8463, Val SMAPE: 183.9486\n",
      "[Epoch 2/50] Train Loss: 4888225.8472, Train SMAPE: 171.7582, Val Loss: 4448748.2196, Val SMAPE: 169.2813\n",
      "[Epoch 3/50] Train Loss: 4573072.0866, Train SMAPE: 156.4626, Val Loss: 4129343.1410, Val SMAPE: 156.0540\n",
      "[Epoch 4/50] Train Loss: 4275938.7128, Train SMAPE: 142.8021, Val Loss: 3828384.9164, Val SMAPE: 144.0239\n",
      "[Epoch 5/50] Train Loss: 3996662.0578, Train SMAPE: 130.5131, Val Loss: 3545259.2855, Val SMAPE: 133.0411\n",
      "[Epoch 6/50] Train Loss: 3734588.6564, Train SMAPE: 119.4131, Val Loss: 3279219.4696, Val SMAPE: 122.9740\n",
      "[Epoch 7/50] Train Loss: 3488986.6778, Train SMAPE: 109.4503, Val Loss: 3029521.2783, Val SMAPE: 113.7078\n",
      "[Epoch 8/50] Train Loss: 3259142.1203, Train SMAPE: 100.8084, Val Loss: 2795463.7390, Val SMAPE: 105.1454\n",
      "[Epoch 9/50] Train Loss: 3044385.4777, Train SMAPE: 93.1636, Val Loss: 2576397.4992, Val SMAPE: 97.2102\n",
      "[Epoch 10/50] Train Loss: 2844096.6265, Train SMAPE: 86.1898, Val Loss: 2371724.6786, Val SMAPE: 89.8587\n",
      "[Epoch 11/50] Train Loss: 2657699.7221, Train SMAPE: 79.8179, Val Loss: 2180891.7052, Val SMAPE: 83.0666\n",
      "[Epoch 12/50] Train Loss: 2484658.1182, Train SMAPE: 74.0124, Val Loss: 2003381.1582, Val SMAPE: 76.7892\n",
      "[Epoch 13/50] Train Loss: 2324464.7920, Train SMAPE: 68.6618, Val Loss: 1838705.4751, Val SMAPE: 70.9366\n",
      "[Epoch 14/50] Train Loss: 2176634.9643, Train SMAPE: 63.7041, Val Loss: 1686394.1102, Val SMAPE: 65.4666\n",
      "[Epoch 15/50] Train Loss: 2040695.8258, Train SMAPE: 59.1038, Val Loss: 1545988.0988, Val SMAPE: 60.3554\n",
      "[Epoch 16/50] Train Loss: 1916181.1400, Train SMAPE: 54.8513, Val Loss: 1417033.0799, Val SMAPE: 55.6314\n",
      "[Epoch 17/50] Train Loss: 1802623.4283, Train SMAPE: 50.9562, Val Loss: 1299074.2780, Val SMAPE: 51.3428\n",
      "[Epoch 18/50] Train Loss: 1699549.4517, Train SMAPE: 47.4249, Val Loss: 1191645.2590, Val SMAPE: 47.5277\n",
      "[Epoch 19/50] Train Loss: 1606472.2717, Train SMAPE: 44.2793, Val Loss: 1094269.5111, Val SMAPE: 44.2831\n",
      "[Epoch 20/50] Train Loss: 1522890.8156, Train SMAPE: 41.5861, Val Loss: 1006448.3764, Val SMAPE: 41.5871\n",
      "[Epoch 21/50] Train Loss: 1448281.5656, Train SMAPE: 39.3970, Val Loss: 927670.4321, Val SMAPE: 39.3845\n",
      "[Epoch 22/50] Train Loss: 1382107.2509, Train SMAPE: 37.6654, Val Loss: 857403.8149, Val SMAPE: 37.5696\n",
      "[Epoch 23/50] Train Loss: 1323809.2518, Train SMAPE: 36.3728, Val Loss: 795095.4488, Val SMAPE: 36.0776\n",
      "[Epoch 24/50] Train Loss: 1272812.7508, Train SMAPE: 35.4464, Val Loss: 740181.6530, Val SMAPE: 34.8227\n",
      "[Epoch 25/50] Train Loss: 1228533.0071, Train SMAPE: 34.7925, Val Loss: 692081.7466, Val SMAPE: 33.7670\n",
      "[Epoch 26/50] Train Loss: 1190375.0326, Train SMAPE: 34.3347, Val Loss: 650209.4661, Val SMAPE: 32.8763\n",
      "[Epoch 27/50] Train Loss: 1157744.2527, Train SMAPE: 34.0275, Val Loss: 613982.4453, Val SMAPE: 32.1240\n"
     ]
    }
   ],
   "source": [
    "submission_result = {}\n",
    "\n",
    "loss_dict = {}  # 건물별 loss 기록 저장\n",
    "\n",
    "drop_cols = ['num_date_time', 'b_num', 'date', 'b_type','total_area']\n",
    "exclude_cols = []\n",
    "seq_length = 24\n",
    "batch_size = 50\n",
    "scaler = StandardScaler()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "epochs = 50\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_dict = {}\n",
    "test_dict = {}\n",
    "\n",
    "for name in change_name:\n",
    "    train_dict[name] = train_merge[train_merge['b_type'] == name].set_index('datetime')\n",
    "    test_dict[name] = test_merge[test_merge['b_type'] == name].set_index('datetime')\n",
    "\n",
    "    train_dict[name].drop(drop_cols, axis=1, inplace=True)\n",
    "    test_dict[name].drop(drop_cols, axis=1, inplace=True)\n",
    "    \n",
    "    train_ex = ['power_consumption']\n",
    "    train_dict[name] = scalering(train_dict[name],train_ex,scaler, fit = True)\n",
    "    test_dict[name] = scalering(test_dict[name],exclude_cols,scaler, fit = False)\n",
    "\n",
    "    tr, vr = train_validation_split(train_dict[name], seq_length)\n",
    "    X_tr, y_tr = make_dataset(tr,seq_length)\n",
    "    X_vr, y_vr = make_dataset(vr,seq_length)\n",
    "    X_test, _ = make_dataset(test_dict[name], seq_length)\n",
    "\n",
    "    train_X_ts = torch.FloatTensor(X_tr)\n",
    "    train_y_ts = torch.FloatTensor(y_tr)\n",
    "    test_X_ts = torch.FloatTensor(X_test).to(device)\n",
    "\n",
    "    val_X_ts = torch.FloatTensor(X_vr)\n",
    "    val_y_ts = torch.FloatTensor(y_vr)\n",
    "\n",
    "    dataset = TensorDataset(train_X_ts, train_y_ts)\n",
    "    dataset_val = TensorDataset(val_X_ts, val_y_ts)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    val_loader = DataLoader(dataset_val, batch_size=batch_size)\n",
    "\n",
    "    input_dim = train_X_ts.shape[2]\n",
    "    model = LSTM(\n",
    "        input_dim = input_dim,\n",
    "        hidden_dim = 30,\n",
    "        output_dim = 1,\n",
    "        seq_length = seq_length,\n",
    "        layers = 1\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    print(f\"[{name} is training]\")\n",
    "    # 건물별 기록\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_smape': [], 'val_smape': []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # -------- Train --------\n",
    "        model.train()\n",
    "        train_loss, train_smape = 0, 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_smape += smape_loss(y_batch, outputs).item()\n",
    "\n",
    "        # -------- Validation --------\n",
    "        model.eval()\n",
    "        val_loss, val_smape = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_smape += smape_loss(y_batch, outputs).item()\n",
    "\n",
    "        # 평균 기록\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        train_smape /= len(train_loader)\n",
    "        val_smape /= len(val_loader)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_smape'].append(train_smape)\n",
    "        history['val_smape'].append(val_smape)\n",
    "\n",
    "        # 디버깅 출력\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"[Epoch {epoch+1}/{epochs}] \"\n",
    "                  f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "                  f\"Train SMAPE: {train_smape:.4f}, Val SMAPE: {val_smape:.4f}\")\n",
    "\n",
    "    # 기록 저장\n",
    "    loss_dict[name] = history\n",
    "    print(\"=\"*120)\n",
    "\n",
    "    # -------- Test 예측 --------\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(test_X_ts), batch_size):\n",
    "            batch = test_X_ts[i:i+batch_size]\n",
    "            output = model(batch)\n",
    "            preds.extend(output.cpu().numpy())\n",
    "\n",
    "    preds = np.array(preds).reshape(-1)\n",
    "\n",
    "    # 결과 저장\n",
    "    submission_result[name] = preds\n",
    "    print(f\"[{name}] Test 예측 shape: {preds.shape}\")\n",
    "    print(\"=\" * 200)\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "# 1) Loss\n",
    "for name, hist in loss_dict.items():\n",
    "    axes[0].plot(hist['train_loss'], label=f\"{name} Train Loss\")\n",
    "    axes[0].plot(hist['val_loss'], linestyle='--', label=f\"{name} Val Loss\")\n",
    "\n",
    "axes[0].set_ylabel(\"MSE Loss\")\n",
    "axes[0].set_title(\"Train/Validation Loss by Building Type\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# 2) SMAPE\n",
    "for name, hist in loss_dict.items():\n",
    "    axes[1].plot(hist['train_smape'], label=f\"{name} Train SMAPE\")\n",
    "    axes[1].plot(hist['val_smape'], linestyle='--', label=f\"{name} Val SMAPE\")\n",
    "\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"SMAPE\")\n",
    "axes[1].set_title(\"Train/Validation SMAPE by Building Type\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98598e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission 불러오기\n",
    "sample_submission = pd.read_csv(submission_path)\n",
    "\n",
    "# 건물 유형별 예측 채워넣기\n",
    "for name in change_name:\n",
    "    sample_submission.loc[sample_submission['b_type'] == name, 'answer'] = submission_result[name]\n",
    "\n",
    "# 저장\n",
    "sample_submission.to_csv(\"../result/0817/LSTM.csv\", index=False)\n",
    "print(\"LSTM.csv 파일이 저장되었습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c775a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16296, 24, 13) (16296, 1)\n",
      "(4080, 24, 13) (4080, 1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213d307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
