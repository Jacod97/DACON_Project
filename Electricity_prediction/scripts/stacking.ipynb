{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7edd7792",
   "metadata": {},
   "source": [
    "## 1. 데이터셋 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a07eedf",
   "metadata": {},
   "source": [
    "### 1. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eb0a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV  # 메타 러너로 안정적\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split, KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce0e54",
   "metadata": {},
   "source": [
    "### 2. 경로 설정 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c1b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/origin/train.csv\"\n",
    "test_path = \"../data/origin/test.csv\"\n",
    "building_path = \"../data/origin/building_info.csv\"\n",
    "submission_path = \"../data/origin/sample_submission.csv\"\n",
    "\n",
    "ko2en_dict = {\n",
    " '건물번호': 'b_num',\n",
    " '일시': 'date',\n",
    " '기온(°C)': 'tmp',\n",
    " '강수량(mm)': 'rain',\n",
    " '풍속(m/s)': 'wind',\n",
    " '습도(%)': 'hum',\n",
    " '일조(hr)': 'sunshine',\n",
    " '일사(MJ/m2)': 'solar',\n",
    " '전력소비량(kWh)': 'power_consumption',\n",
    " '건물유형': 'b_type',\n",
    " '연면적(m2)': 'total_area',\n",
    " '냉방면적(m2)': 'cooling_area',\n",
    " '태양광용량(kW)': 'solar_capacity',\n",
    " 'ESS저장용량(kWh)': 'ess_capacity',\n",
    " 'PCS용량(kW)': 'pcs_capacity',\n",
    "}\n",
    "\n",
    "change_name = ['hotel', 'commercial', 'hospital', 'school', 'etc', 'apart', 'research', 'store', 'idc','public']\n",
    "\n",
    "train = pd.read_csv(train_path, encoding='utf-8')\n",
    "test = pd.read_csv(test_path, encoding='utf-8')\n",
    "building = pd.read_csv(building_path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1b569",
   "metadata": {},
   "source": [
    "### 3. 시계열 변환 및 건물별 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "553df441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_dataframe_columns(df, mapping_dict):\n",
    "    return df.rename(columns=mapping_dict).copy()\n",
    "\n",
    "def add_time(df):\n",
    "    df['datetime'] = pd.to_datetime(df['date'], format='%Y%m%d %H')\n",
    "    df['weekday'] = df['datetime'].dt.weekday\n",
    "    df['time'] = df['datetime'].dt.hour\n",
    "    \n",
    "    df['month_day'] = df['datetime'].dt.strftime(\"%m-%d\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1062b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>b_num</th>\n",
       "      <th>date</th>\n",
       "      <th>tmp</th>\n",
       "      <th>rain</th>\n",
       "      <th>wind</th>\n",
       "      <th>hum</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>solar</th>\n",
       "      <th>power_consumption</th>\n",
       "      <th>datetime</th>\n",
       "      <th>weekday</th>\n",
       "      <th>time</th>\n",
       "      <th>month_day</th>\n",
       "      <th>b_type</th>\n",
       "      <th>total_area</th>\n",
       "      <th>cooling_area</th>\n",
       "      <th>solar_capacity</th>\n",
       "      <th>ess_capacity</th>\n",
       "      <th>pcs_capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20240601 00</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 00</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5794.80</td>\n",
       "      <td>2024-06-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20240601 01</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 01</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5591.85</td>\n",
       "      <td>2024-06-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20240601 02</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 02</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5338.17</td>\n",
       "      <td>2024-06-01 02:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20240601 03</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 03</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4554.42</td>\n",
       "      <td>2024-06-01 03:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20240601 04</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 04</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3602.25</td>\n",
       "      <td>2024-06-01 04:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_date_time  b_num         date   tmp  rain  wind   hum  sunshine  solar  \\\n",
       "0  1_20240601 00      1  20240601 00  18.3   0.0   2.6  82.0       0.0    0.0   \n",
       "1  1_20240601 01      1  20240601 01  18.3   0.0   2.7  82.0       0.0    0.0   \n",
       "2  1_20240601 02      1  20240601 02  18.1   0.0   2.6  80.0       0.0    0.0   \n",
       "3  1_20240601 03      1  20240601 03  18.0   0.0   2.6  81.0       0.0    0.0   \n",
       "4  1_20240601 04      1  20240601 04  17.8   0.0   1.3  81.0       0.0    0.0   \n",
       "\n",
       "   power_consumption            datetime  weekday  time  month_day b_type  \\\n",
       "0            5794.80 2024-06-01 00:00:00        5     0          0  hotel   \n",
       "1            5591.85 2024-06-01 01:00:00        5     1          0  hotel   \n",
       "2            5338.17 2024-06-01 02:00:00        5     2          0  hotel   \n",
       "3            4554.42 2024-06-01 03:00:00        5     3          0  hotel   \n",
       "4            3602.25 2024-06-01 04:00:00        5     4          0  hotel   \n",
       "\n",
       "   total_area  cooling_area solar_capacity ess_capacity pcs_capacity  \n",
       "0    82912.71       77586.0              -            -            -  \n",
       "1    82912.71       77586.0              -            -            -  \n",
       "2    82912.71       77586.0              -            -            -  \n",
       "3    82912.71       77586.0              -            -            -  \n",
       "4    82912.71       77586.0              -            -            -  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num_date_time', 'b_num', 'date', 'tmp', 'rain', 'wind', 'hum', 'sunshine', 'solar', 'power_consumption', 'datetime', 'weekday', 'time', 'month_day', 'b_type', 'total_area', 'cooling_area', 'solar_capacity', 'ess_capacity', 'pcs_capacity']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>b_num</th>\n",
       "      <th>date</th>\n",
       "      <th>tmp</th>\n",
       "      <th>rain</th>\n",
       "      <th>wind</th>\n",
       "      <th>hum</th>\n",
       "      <th>datetime</th>\n",
       "      <th>weekday</th>\n",
       "      <th>time</th>\n",
       "      <th>month_day</th>\n",
       "      <th>b_type</th>\n",
       "      <th>total_area</th>\n",
       "      <th>cooling_area</th>\n",
       "      <th>solar_capacity</th>\n",
       "      <th>ess_capacity</th>\n",
       "      <th>pcs_capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20240825 00</td>\n",
       "      <td>1</td>\n",
       "      <td>20240825 00</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2024-08-25 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20240825 01</td>\n",
       "      <td>1</td>\n",
       "      <td>20240825 01</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2024-08-25 01:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20240825 02</td>\n",
       "      <td>1</td>\n",
       "      <td>20240825 02</td>\n",
       "      <td>25.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2024-08-25 02:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20240825 03</td>\n",
       "      <td>1</td>\n",
       "      <td>20240825 03</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2024-08-25 03:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20240825 04</td>\n",
       "      <td>1</td>\n",
       "      <td>20240825 04</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2024-08-25 04:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>hotel</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_date_time  b_num         date   tmp  rain  wind   hum  \\\n",
       "0  1_20240825 00      1  20240825 00  26.5   0.0   0.7  80.0   \n",
       "1  1_20240825 01      1  20240825 01  26.1   0.0   0.0  80.0   \n",
       "2  1_20240825 02      1  20240825 02  25.9   0.0   0.3  83.0   \n",
       "3  1_20240825 03      1  20240825 03  25.7   0.0   1.1  83.0   \n",
       "4  1_20240825 04      1  20240825 04  25.5   0.0   1.0  86.0   \n",
       "\n",
       "             datetime  weekday  time  month_day b_type  total_area  \\\n",
       "0 2024-08-25 00:00:00        6     0         85  hotel    82912.71   \n",
       "1 2024-08-25 01:00:00        6     1         85  hotel    82912.71   \n",
       "2 2024-08-25 02:00:00        6     2         85  hotel    82912.71   \n",
       "3 2024-08-25 03:00:00        6     3         85  hotel    82912.71   \n",
       "4 2024-08-25 04:00:00        6     4         85  hotel    82912.71   \n",
       "\n",
       "   cooling_area solar_capacity ess_capacity pcs_capacity  \n",
       "0       77586.0              -            -            -  \n",
       "1       77586.0              -            -            -  \n",
       "2       77586.0              -            -            -  \n",
       "3       77586.0              -            -            -  \n",
       "4       77586.0              -            -            -  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num_date_time', 'b_num', 'date', 'tmp', 'rain', 'wind', 'hum', 'datetime', 'weekday', 'time', 'month_day', 'b_type', 'total_area', 'cooling_area', 'solar_capacity', 'ess_capacity', 'pcs_capacity']\n"
     ]
    }
   ],
   "source": [
    "train_df = rename_dataframe_columns(train, ko2en_dict)\n",
    "test_df = rename_dataframe_columns(test, ko2en_dict)\n",
    "building_info_df = rename_dataframe_columns(building, ko2en_dict)\n",
    "\n",
    "train_df = add_time(train_df)\n",
    "test_df = add_time(test_df)\n",
    "\n",
    "train_merge = pd.merge(train_df, building_info_df, on='b_num', how='left')\n",
    "test_merge = pd.merge(test_df, building_info_df, on='b_num', how='left')\n",
    "\n",
    "le = LabelEncoder()\n",
    "all_values = pd.concat([train_merge['month_day'], test_merge['month_day']])\n",
    "le.fit(all_values)\n",
    "\n",
    "train_merge['month_day'] = le.transform(train_merge['month_day'])\n",
    "test_merge['month_day'] = le.transform(test_merge['month_day'])\n",
    "\n",
    "btypes = list(building_info_df['b_type'].unique())\n",
    "type_map = {bt: change_name[i] for i, bt in enumerate(btypes)}\n",
    "train_merge['b_type'] = train_merge['b_type'].apply(lambda x : type_map[x])\n",
    "test_merge['b_type'] = test_merge['b_type'].apply(lambda x : type_map[x])\n",
    "\n",
    "display(train_merge.head())\n",
    "print(list(train_merge.columns))\n",
    "display(test_merge.head())\n",
    "print(list(test_merge.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065bfcf1",
   "metadata": {},
   "source": [
    "## 2. 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cdf4ea",
   "metadata": {},
   "source": [
    "### 1. 유틸 함수 및 모델 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33486f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_process(df, threshold=2.0):\n",
    "    '''이상치 처리 메서드'''\n",
    "    df = df.copy()\n",
    "    for key, group in df.groupby(\"b_num\"):\n",
    "        idx = group.index\n",
    "        vals = group[\"power_consumption\"].to_numpy()\n",
    "        for i in range(1, len(vals) - 1):\n",
    "            if vals[i-1] == 0: \n",
    "                continue\n",
    "            ratio = vals[i] / vals[i-1]\n",
    "            if ratio >= threshold or ratio <= 1/threshold:\n",
    "                vals[i] = (vals[i-1] + vals[i+1]) / 2\n",
    "        df.loc[idx, \"power_consumption\"] = vals\n",
    "    return df\n",
    "\n",
    "def is_drop(df, col):\n",
    "    '''col 값이 모두 같으면 True (즉, 상수 컬럼이면 제거 대상)'''\n",
    "    return df[col].nunique(dropna=False) <= 1\n",
    "    \n",
    "def convert_day(df, threshold=0.018):\n",
    "    '''주말의 평균 전력사용량과 평일의 전력사용량의 비율 차이가 0.018 이상 차이나면 범주화'''\n",
    "    gb = df.groupby(['weekday']).mean(numeric_only=True)\n",
    "\n",
    "    workday = (sum(gb['power_consumption'].iloc[0:5])/5)/sum(gb['power_consumption']) \n",
    "    holiday = (sum(gb['power_consumption'].iloc[5:])/2)/sum(gb['power_consumption'])\n",
    "    if workday - holiday > threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def minmax_scale(df: pd.DataFrame, exclude_cols, scaler,fit):\n",
    "    '''MinMax Scalering 적용'''\n",
    "    target_cols = [i for i in df.columns if i not in exclude_cols]\n",
    "    if fit:\n",
    "        df[target_cols] = scaler.fit_transform(df[target_cols])\n",
    "    else:\n",
    "        df[target_cols] = scaler.transform(df[target_cols])\n",
    "    return df\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(\n",
    "        2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-9)\n",
    "    )\n",
    "smape_scorer = make_scorer(lambda y_true, y_pred: -smape(y_true, y_pred))\n",
    "\n",
    "default_params = {\n",
    "    \"XGB\": {\n",
    "        \"n_estimators\": 1000,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\": 7,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"verbosity\": 0  \n",
    "    },\n",
    "    \"LGBM\": {\n",
    "        \"n_estimators\": 1000,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\": -1,\n",
    "        \"num_leaves\": 63,\n",
    "        \"subsample\": 0.8,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"verbose\": -1   \n",
    "    },\n",
    "    \"RF\": {\n",
    "        \"n_estimators\": 1000,\n",
    "        \"max_depth\": None,\n",
    "        \"min_samples_split\": 2,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"max_features\": \"sqrt\",\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        \"iterations\": 1000,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"depth\": 7,\n",
    "        \"l2_leaf_reg\": 3,\n",
    "        \"subsample\": 0.8,\n",
    "        \"random_seed\": 42,\n",
    "        \"verbose\": 0,\n",
    "        \"task_type\": \"CPU\",\n",
    "        \"loss_function\": \"RMSE\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc27e2",
   "metadata": {},
   "source": [
    "### 2. 학습 및 피처 엔지니어링 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b9a999b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_date_time                object\n",
       "b_num                         int64\n",
       "date                         object\n",
       "tmp                         float64\n",
       "rain                        float64\n",
       "wind                        float64\n",
       "hum                         float64\n",
       "sunshine                    float64\n",
       "solar                       float64\n",
       "power_consumption           float64\n",
       "datetime             datetime64[ns]\n",
       "weekday                       int32\n",
       "time                          int32\n",
       "month_day                     int64\n",
       "b_type                       object\n",
       "total_area                  float64\n",
       "cooling_area                float64\n",
       "solar_capacity               object\n",
       "ess_capacity                 object\n",
       "pcs_capacity                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = train_merge.replace(\"-\", 0)\n",
    "tt.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13f7ad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gd980\\AppData\\Local\\Temp\\ipykernel_17220\\2505103647.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_type_df = train_type_df.replace(\"-\", 0).apply(pd.to_numeric, errors=\"coerce\")\n",
      "C:\\Users\\gd980\\AppData\\Local\\Temp\\ipykernel_17220\\2505103647.py:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_type_df = test_type_df.replace(\"-\", 0).apply(pd.to_numeric, errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hotel]\n",
      "hotel XGB SMAPE: 6.9025\n",
      "hotel LGBM SMAPE: 6.8997\n",
      "hotel RF SMAPE: 7.6552\n",
      "hotel CatBoost SMAPE: 7.7069\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 100\u001b[39m\n\u001b[32m     91\u001b[39m stacking = StackingRegressor(\n\u001b[32m     92\u001b[39m     estimators=base_estimators,\n\u001b[32m     93\u001b[39m     final_estimator=meta_est,\n\u001b[32m   (...)\u001b[39m\u001b[32m     96\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     97\u001b[39m )\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# 홀드아웃 검증\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[43mstacking\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m stack_val = stacking.predict(X_vr)\n\u001b[32m    102\u001b[39m stack_score = smape(y_vr, stack_val)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gd980\\miniconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:1043\u001b[39m, in \u001b[36mStackingRegressor.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m   1039\u001b[39m _raise_for_params(fit_params, \u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, allow=[\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1041\u001b[39m y = column_or_1d(y, warn=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gd980\\miniconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gd980\\miniconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:211\u001b[39m, in \u001b[36m_BaseStacking.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    206\u001b[39m             \u001b[38;5;28mself\u001b[39m.estimators_.append(estimator)\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    208\u001b[39m     \u001b[38;5;66;03m# Fit the base estimators on the whole training data. Those\u001b[39;00m\n\u001b[32m    209\u001b[39m     \u001b[38;5;66;03m# base estimators will be used in transform, predict, and\u001b[39;00m\n\u001b[32m    210\u001b[39m     \u001b[38;5;66;03m# predict_proba. They are exposed publicly.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28mself\u001b[39m.estimators_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_estimators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdrop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28mself\u001b[39m.named_estimators_ = Bunch()\n\u001b[32m    220\u001b[39m est_fitted_idx = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gd980\\miniconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gd980\\miniconda3\\envs\\myenv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gd980\\miniconda3\\envs\\myenv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gd980\\miniconda3\\envs\\myenv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "result = {}\n",
    "best_score_ever = 0\n",
    "view_results = {tp: {} for tp in change_name}\n",
    "\n",
    "train_merge = outlier_process(train_merge)\n",
    "\n",
    "for tp in change_name:\n",
    "    exclude_list = ['time', 'tmp', 'month_day']\n",
    "    drop_cols = ['num_date_time', 'b_num', 'date','datetime', 'b_type','rain', 'sunshine', 'solar']\n",
    "\n",
    "    train_type_df = train_merge[train_merge['b_type'] == tp].reset_index(drop=True)\n",
    "    test_type_df = test_merge[test_merge['b_type'] == tp].reset_index(drop=True)\n",
    "\n",
    "    train_type_df = train_type_df.replace(\"-\", 0).apply(pd.to_numeric, errors=\"coerce\")\n",
    "    test_type_df = test_type_df.replace(\"-\", 0).apply(pd.to_numeric, errors=\"coerce\")\n",
    "    \n",
    "    for col in train_type_df.columns:\n",
    "        if is_drop(train_type_df, col) and col not in drop_cols:\n",
    "            drop_cols.append(col)\n",
    "    \n",
    "    if convert_day(train_type_df):\n",
    "        train_type_df['weekday'] = train_type_df['weekday'].apply(lambda x: 0 if x < 5 else 1)\n",
    "        test_type_df['weekday'] = test_type_df['weekday'].apply(lambda x: 0 if x < 5 else 1)\n",
    "        exclude_list.append('weekday')\n",
    "    else:\n",
    "        drop_cols.append('weekday')\n",
    "\n",
    "    train_type_df.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "    train_type_df.fillna(0, inplace=True)\n",
    "    test_type_df.fillna(0, inplace=True)\n",
    "\n",
    "    y_train = train_type_df['power_consumption'].copy()\n",
    "    X_train = train_type_df.drop(columns=['power_consumption']).copy()\n",
    "    X_test = test_type_df[X_train.columns]\n",
    "\n",
    "    exclude_train = exclude_list + ['power_consumption']  \n",
    "    exclude_test = exclude_list                           \n",
    "\n",
    "    X_tr, X_vr, y_tr, y_vr = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # X_tr = minmax_scale(X_train, exclude_train, scaler, True)\n",
    "    # X_vr = minmax_scale(X_test, exclude_test, scaler, False)\n",
    "    # X_test = minmax_scale(X_test, exclude_test, scaler, False)\n",
    "\n",
    "    model_builders = {\n",
    "        \"XGB\": lambda: XGBRegressor(**default_params[\"XGB\"]),\n",
    "        \"LGBM\": lambda: LGBMRegressor(**default_params[\"LGBM\"]),\n",
    "        \"RF\": lambda: RandomForestRegressor(**default_params[\"RF\"]),\n",
    "        \"CatBoost\": lambda: CatBoostRegressor(**{**default_params[\"CatBoost\"], \"verbose\": False})\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_score = float('inf')\n",
    "    best_name = None\n",
    "\n",
    "    print(f\"[{tp}]\")\n",
    "    fitted_models = {}\n",
    "    val_preds = []\n",
    "\n",
    "    # ---- 단일 모델 성능 측정 (홀드아웃) ----\n",
    "    for name, build_model in model_builders.items():\n",
    "        model = build_model()\n",
    "        model.fit(X_tr, y_tr)\n",
    "        val_pred = model.predict(X_vr)\n",
    "        score = smape(y_vr, val_pred)\n",
    "\n",
    "        # 시각화용: 학습 전체(X_train) 예측 저장\n",
    "        train_pred = model.predict(X_train)\n",
    "        view_results[tp][name] = (y_train.values, train_pred)\n",
    "\n",
    "        print(f\"{tp} {name} SMAPE: {score:.4f}\")\n",
    "        val_preds.append(val_pred)\n",
    "        fitted_models[name] = model\n",
    "\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "            best_name = name\n",
    "\n",
    "    # ---- 스태킹 앙상블 구성 ----\n",
    "    base_estimators = [\n",
    "        ('xgb',  clone(model_builders[\"XGB\"]())),\n",
    "        ('lgbm', clone(model_builders[\"LGBM\"]())),\n",
    "        ('rf',   clone(model_builders[\"RF\"]())),\n",
    "        ('cb',   clone(model_builders[\"CatBoost\"]())),\n",
    "    ]\n",
    "    meta_est = RidgeCV(alphas=(0.1, 1.0, 10.0))\n",
    "\n",
    "    stacking = StackingRegressor(\n",
    "        estimators=base_estimators,\n",
    "        final_estimator=meta_est,\n",
    "        cv=5,               # 내부 OOF 생성\n",
    "        passthrough=True,   # 원특성 + base 예측 함께 사용\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # 홀드아웃 검증\n",
    "    stacking.fit(X_tr, y_tr)\n",
    "    stack_val = stacking.predict(X_vr)\n",
    "    stack_score = smape(y_vr, stack_val)\n",
    "    print(f\"{tp} Stacking SMAPE: {stack_score:.4f}\")\n",
    "\n",
    "    # ---- 최종 선택 & Test 예측 ----\n",
    "    if stack_score < best_score:\n",
    "        print(f\"==> Stacking chosen for {tp} (SMAPE: {stack_score:.4f})\")\n",
    "        # 전체 학습데이터로 재학습 후 테스트 예측\n",
    "        stacking.fit(X_train, y_train)\n",
    "        test_pred = stacking.predict(X_test)\n",
    "        final_score = stack_score\n",
    "\n",
    "        # 시각화 저장\n",
    "        view_results[tp][\"Stacking\"] = (y_train.values, stacking.predict(X_train))\n",
    "    else:\n",
    "        print(f\"==> {best_name} chosen for {tp} (SMAPE: {best_score:.4f})\")\n",
    "        # 동일한 빌더로 새 모델 생성하여 전체 학습데이터로 재학습\n",
    "        best_model_full = clone(model_builders[best_name]())\n",
    "        best_model_full.fit(X_train, y_train)\n",
    "        test_pred = best_model_full.predict(X_test)\n",
    "        final_score = best_score\n",
    "\n",
    "        # (선택) 시각화 저장 갱신 원하면 아래 라인 사용\n",
    "        # view_results[tp][best_name] = (y_train.values, best_model_full.predict(X_train))\n",
    "\n",
    "    # 결과 집계\n",
    "    result[tp] = test_pred\n",
    "    best_score_ever += final_score\n",
    "    print(\"=\" * 100)\n",
    "# ================== 여기까지 교체 ==================\n",
    "\n",
    "print(f\"Average over all building types: {(best_score_ever/10):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50913f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"XGB\": \"red\", \"LGBM\": \"blue\", \"RF\": \"green\", \"CatBoost\": \"black\"}\n",
    "\n",
    "for tp in change_name:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for model_name, fold_data in view_results[tp].items():\n",
    "        # fold_data = [(val_idx, score), ...]\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for val_idx, score in fold_data:\n",
    "            xs.extend(val_idx)         # 실제 시계열 인덱스\n",
    "            ys.extend([score]*len(val_idx))  # 같은 fold는 같은 score로 채움\n",
    "\n",
    "        plt.plot(xs, ys, marker='.', color=colors[model_name], label=model_name)\n",
    "\n",
    "    plt.title(f\"SMAPE by Time Index - {tp}\")\n",
    "    plt.xlabel(\"Time Index (row order)\")\n",
    "    plt.ylabel(\"SMAPE\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a16dc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 완료: baseline_submission.csv\n"
     ]
    }
   ],
   "source": [
    "y_out = np.zeros(len(test_merge))\n",
    "for tp in change_name:\n",
    "    idx = test_merge.index[test_merge['b_type'] == tp].tolist()\n",
    "    y_out[idx] = result[tp]\n",
    "\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission['answer'] = y_out\n",
    "submission.to_csv(\"../result/0817/ML_0817_03.csv\", index=False)\n",
    "print(\"저장 완료: baseline_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08120c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
