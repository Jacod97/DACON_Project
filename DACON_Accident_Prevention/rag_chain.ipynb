{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from ollama import ChatOllama  # 사용한 LLM이 Ollama API로 추정됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 메타데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 설정\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 메타데이터 분류 (전역 변수)\n",
    "metadata_categories = {\n",
    "    \"construction_type\": {\n",
    "        '건축': ['건축물', '건설공사', '건설현장', '건설기계', '건설업체'],\n",
    "        '토목': ['교량', '터널', '도로', '철도', '항만', '하천'],\n",
    "        '조경': ['조경', '수목', '식재'],\n",
    "        '설비': ['설비', '플랜트', '시스템', '기계'],\n",
    "        '기타': []\n",
    "    },\n",
    "    \"work_type\": {\n",
    "        '기초공사': ['기초', '말뚝', '지하', '굴착'],\n",
    "        '구조공사': ['철골', '콘크리트', '거푸집', '동바리'],\n",
    "        '설비공사': ['설비', '배관', '전기', '용접'],\n",
    "        '마감공사': ['미장', '타일', '도배', '페인트'],\n",
    "        '기타': []\n",
    "    },\n",
    "    \"accident_type\": {\n",
    "        '추락': ['추락', '고소', '비계', '발판'],\n",
    "        '낙하': ['낙하', '물체', '중량물'],\n",
    "        '굴착': ['굴착', '터널', '지하'],\n",
    "        '감전': ['전기', '감전'],\n",
    "        '기타': []\n",
    "    },\n",
    "    \"accident_object\": {\n",
    "        '건설기계': ['크레인', '펌프', '굴착기', '타워크레인'],\n",
    "        '건설자재': ['철근', '콘크리트', '거푸집', '동바리'],\n",
    "        '설비': ['전기설비', '배관', '용접기'],\n",
    "        '기타': []\n",
    "    }\n",
    "}\n",
    "\n",
    "# 파일명에서 메타데이터 추출\n",
    "def extract_metadata_from_filename(filename):\n",
    "    filename = os.path.splitext(filename)[0]\n",
    "    metadata = {key: \"기타\" for key in metadata_categories}\n",
    "\n",
    "    for meta_key, category_dict in metadata_categories.items():\n",
    "        for category, keywords in category_dict.items():\n",
    "            if any(keyword in filename for keyword in keywords):\n",
    "                metadata[meta_key] = category\n",
    "                break  \n",
    "\n",
    "    return metadata\n",
    "\n",
    "# 질문에서 키워드 추출하여 필터링 적용\n",
    "def get_dynamic_filters(question):\n",
    "    filters = {}\n",
    "\n",
    "    for filter_key, category_dict in metadata_categories.items():\n",
    "        for category, keywords in category_dict.items():\n",
    "            if any(keyword in question for keyword in keywords):\n",
    "                filters[filter_key] = category\n",
    "                break  \n",
    "\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검색 및 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 함수 (검색 후 메타데이터 필터링 적용)\n",
    "def search_similar_sections(query, vectorstore, filters=None, k=5):\n",
    "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "    \n",
    "    if filters:\n",
    "        filtered_results = []\n",
    "        for doc, score in results:\n",
    "            match = all(doc.metadata.get(key, \"기타\") == value for key, value in filters.items())\n",
    "            if match:\n",
    "                filtered_results.append((doc, score))\n",
    "        results = filtered_results\n",
    "\n",
    "    return [{\n",
    "        'section': doc.page_content,\n",
    "        'similarity': 1 - score,\n",
    "        'metadata': doc.metadata\n",
    "    } for doc, score in results]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector DB 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 데이터베이스 생성\n",
    "def create_vector_database(documents, model_name='jhgan/ko-sbert-sts', batch_size=32):\n",
    "    print(f\"총 {len(documents)}개의 문서를 처리하여 벡터 데이터베이스를 생성합니다.\")\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs={'device': device})\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1300, chunk_overlap=100)\n",
    "\n",
    "    texts, metadatas = [], []\n",
    "    for i in tqdm(range(0, len(documents), batch_size)):\n",
    "        batch_docs = documents[i:i + batch_size]\n",
    "        for doc in batch_docs:\n",
    "            splits = text_splitter.split_text(doc[\"content\"])\n",
    "            if len(splits) == 0:\n",
    "                print(f\"경고: {doc['metadata']['filename']} 문서에서 텍스트를 추출하지 못함!\")\n",
    "                continue\n",
    "            texts.extend(splits)\n",
    "            metadatas.extend([doc[\"metadata\"]] * len(splits))\n",
    "\n",
    "    print(f\"총 {len(texts)}개의 텍스트 조각이 생성되었습니다.\")\n",
    "    \n",
    "    if len(texts) == 0:\n",
    "        raise ValueError(\"오류: 벡터화할 텍스트가 없습니다. 문서 로드를 확인하세요!\")\n",
    "\n",
    "    return FAISS.from_texts(texts, embedding=embeddings, metadatas=metadatas)\n",
    "\n",
    "def create_embeddings_batch(texts: List[str], model_name: str = \"jhgan/ko-sbert-sts\", batch_size: int = 32):\n",
    "    \"\"\"배치 처리로 임베딩 생성 (GPU 가속 적용)\"\"\"\n",
    "    embedding = SentenceTransformer(model_name)\n",
    "    embedding.to(device)  # GPU로 모델 이동\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"임베딩 생성 중\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        batch_embeddings = embedding.encode(\n",
    "            batch,\n",
    "            show_progress_bar=False,\n",
    "            device=device,\n",
    "            convert_to_numpy=True\n",
    "        )\n",
    "        embeddings.append(batch_embeddings)\n",
    "    \n",
    "    return np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_rag_batch(rag_chain, questions: List[str], batch_size: int = 8):\n",
    "    \"\"\"RAG 처리 배치 (GPU 가속 적용)\"\"\"\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(questions), batch_size), desc=\"RAG 처리 중\"):\n",
    "        batch_questions = questions[i:i + batch_size]\n",
    "        batch_results = []\n",
    "        for question in batch_questions:\n",
    "            # GPU 메모리 정리\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            result = rag_chain.invoke({\"question\": question})\n",
    "            \n",
    "            batch_results.append(result)\n",
    "        results.extend(batch_results)\n",
    "        if i % 50 == 0:\n",
    "            print(f\"답변 : {result}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "vector_db_path = f\"./db/{timestamp}\"\n",
    "txt_path = \"/home/wanted-1/potenup-workspace/Project/dacon/DACON-construction-accident-prevention/data/pdf_txt\"\n",
    "\n",
    "os.makedirs(vector_db_path, exist_ok=True)\n",
    "txt_files = glob.glob(os.path.join(txt_path, '*.txt'))\n",
    "documents = [{'file_path': f, 'filename': os.path.basename(f)} for f in txt_files]\n",
    "\n",
    "processed_documents = []\n",
    "for doc in tqdm(documents, desc=\"문서 처리 중\"):\n",
    "    try:\n",
    "        with open(doc['file_path'], 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            metadata = extract_metadata_from_filename(doc['filename'])\n",
    "            processed_documents.append({\"metadata\": metadata, \"content\": content})\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {doc['filename']}: {str(e)}\")\n",
    "\n",
    "vectorstore = create_vector_database(processed_documents, batch_size=32)\n",
    "vectorstore.save_local(vector_db_path)\n",
    "\n",
    "template = '''\n",
    "{context}\n",
    "\n",
    "### 질문:\n",
    "{question}\n",
    "\n",
    "### 지침: 당신은 건설 안전 전문가입니다.\n",
    "테스트 데이터에 주어진 사고 상황에 대해, 검색된 문맥을 참고하여 답변을 한 문장으로 작성해 주세요.\n",
    "- 서론, 부연 설명 없이 핵심 단어와 문구만 포함합니다.\n",
    "- 최대 100 토큰 이하로만 간결하게 작성하세요.\n",
    "- 대책에 대한 상세 설명을 적지 말고 대책만 예시처럼 작성하세요.\n",
    "- 특수문자 를 추가하지말고 나열하세요.\n",
    "- \",\"(comma) 사용을 최대한 줄여주세요 \n",
    "- 예시: \"안전관리 시스템 강화 및 사고 예방 프로토콜 개선\"\n",
    "\n",
    "[/INST]\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOllama(model='gemma3:27b', temperature=0.0)\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        'context': lambda inputs: \"\\n\\n\".join([res['section'] for res in search_similar_sections(\n",
    "            inputs['question'], vectorstore, filters=get_dynamic_filters(inputs['question']), k=3\n",
    "        )]),\n",
    "        'question': itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 테스트 실행 및 결과 저장\n",
    "print(\"테스트 실행 시작... 총 테스트 샘플 수:\", len(combined_test_data))\n",
    "\n",
    "questions = combined_test_data['question'].tolist()\n",
    "test_results = process_rag_batch(rag_chain, questions, batch_size=8)\n",
    "pred_embeddings = create_embeddings_batch(test_results, batch_size=32)\n",
    "\n",
    "# 결과 저장\n",
    "submission = pd.read_csv('/home/wanted-1/potenup-workspace/Project/dacon/DACON-construction-accident-prevention/sample_submission.csv', encoding='utf-8-sig')\n",
    "submission.iloc[:,1] = test_results\n",
    "submission.iloc[:,2:] = pred_embeddings\n",
    "\n",
    "# 최종 결과를 CSV로 저장\n",
    "submission.to_csv(f'./{timestamp}_submission.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DACON_env311_cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
